{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d1c5b81-10d0-4d45-bda5-681651cf547d",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook uses the transformer neural network from this repository.\n",
    "\n",
    "It uses a custom dataset class instead of the the Multi30K class from PyTorch. This notebook can be adapated to any other translation dataset if the CSV file can be prepared in the same format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8feed167",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from typing import Iterable, List\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from timeit import default_timer as timer\n",
    "from attention import transformer\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "657b42d4-4062-4415-95d5-bdef7956c674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed.\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3c92e25-0c84-47b4-8733-c75d9e95a67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_LANGUAGE = 'de'\n",
    "TGT_LANGUAGE = 'en'\n",
    "\n",
    "# Place-holders\n",
    "token_transform = {}\n",
    "vocab_transform = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa7e6184-3067-4368-a5ce-64d0f95a282c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-28 07:26:24.825818: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-28 07:26:25.536640: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-06-28 07:26:26.343391: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-06-28 07:26:26.343683: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='de_core_news_sm')\n",
    "token_transform[TGT_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddb4c1af-4425-4faf-88b3-98f19df4dc8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>german</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Two young, White males are outside near many b...</td>\n",
       "      <td>Zwei junge weiße Männer sind im Freien in der ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Several men in hard hats are operating a giant...</td>\n",
       "      <td>Mehrere Männer mit Schutzhelmen bedienen ein A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A little girl climbing into a wooden playhouse.</td>\n",
       "      <td>Ein kleines Mädchen klettert in ein Spielhaus ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A man in a blue shirt is standing on a ladder ...</td>\n",
       "      <td>Ein Mann in einem blauen Hemd steht auf einer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Two men are at the stove preparing food.</td>\n",
       "      <td>Zwei Männer stehen am Herd und bereiten Essen zu.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             english   \n",
       "0  Two young, White males are outside near many b...  \\\n",
       "1  Several men in hard hats are operating a giant...   \n",
       "2    A little girl climbing into a wooden playhouse.   \n",
       "3  A man in a blue shirt is standing on a ladder ...   \n",
       "4           Two men are at the stove preparing food.   \n",
       "\n",
       "                                              german  \n",
       "0  Zwei junge weiße Männer sind im Freien in der ...  \n",
       "1  Mehrere Männer mit Schutzhelmen bedienen ein A...  \n",
       "2  Ein kleines Mädchen klettert in ein Spielhaus ...  \n",
       "3  Ein Mann in einem blauen Hemd steht auf einer ...  \n",
       "4  Zwei Männer stehen am Herd und bereiten Essen zu.  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv = pd.read_csv('data/english_german/translation_train.csv', usecols=['english', 'german'])\n",
    "train_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddcb861f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>german</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A man in an orange hat starring at something.</td>\n",
       "      <td>Ein Mann mit einem orangefarbenen Hut, der etw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Boston Terrier is running on lush green gras...</td>\n",
       "      <td>Ein Boston Terrier läuft über saftig-grünes Gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A girl in karate uniform breaking a stick with...</td>\n",
       "      <td>Ein Mädchen in einem Karateanzug bricht einen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Five people wearing winter jackets and helmets...</td>\n",
       "      <td>Fünf Leute in Winterjacken und mit Helmen steh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>People are fixing the roof of a house.</td>\n",
       "      <td>Leute Reparieren das Dach eines Hauses.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             english   \n",
       "0      A man in an orange hat starring at something.  \\\n",
       "1  A Boston Terrier is running on lush green gras...   \n",
       "2  A girl in karate uniform breaking a stick with...   \n",
       "3  Five people wearing winter jackets and helmets...   \n",
       "4             People are fixing the roof of a house.   \n",
       "\n",
       "                                              german  \n",
       "0  Ein Mann mit einem orangefarbenen Hut, der etw...  \n",
       "1  Ein Boston Terrier läuft über saftig-grünes Gr...  \n",
       "2  Ein Mädchen in einem Karateanzug bricht einen ...  \n",
       "3  Fünf Leute in Winterjacken und mit Helmen steh...  \n",
       "4            Leute Reparieren das Dach eines Hauses.  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_csv = pd.read_csv('data/english_german/translation_test.csv', usecols=['english', 'german'])\n",
    "valid_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db9dcaa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv['german'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708903b8",
   "metadata": {},
   "source": [
    "## Create a Custom Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09724a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, csv):\n",
    "        self.csv = csv\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.csv)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return(\n",
    "            self.csv['german'].iloc[idx],\n",
    "            self.csv['english'].iloc[idx]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "289fbf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TranslationDataset(train_csv)\n",
    "valid_dataset = TranslationDataset(valid_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ceef988d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.', 'Two young, White males are outside near many bushes.')\n"
     ]
    }
   ],
   "source": [
    "iterator = iter(train_dataset)\n",
    "print(next(iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "042737e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to yield list of tokens\n",
    "def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n",
    "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
    "\n",
    "    for data_sample in data_iter:\n",
    "        yield token_transform[language](data_sample[language_index[language]])\n",
    "\n",
    "# Define special symbols and indices\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
    "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
    "\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    # Create torchtext's Vocab object\n",
    "    vocab_transform[ln] = build_vocab_from_iterator(\n",
    "        yield_tokens(train_dataset, ln),\n",
    "        min_freq=1,\n",
    "        specials=special_symbols,\n",
    "        special_first=True,\n",
    "    )\n",
    "\n",
    "# Set ``UNK_IDX`` as the default index. This index is returned when the token is not found.\n",
    "# If not set, it throws ``RuntimeError`` when the queried token is not found in the Vocabulary.\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    vocab_transform[ln].set_default_index(UNK_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa4edb4",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bf0d1bf-6545-432e-893a-bb0341f1d1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
    "TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
    "EMB_SIZE = 512\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "BATCH_SIZE = 128\n",
    "MAX_LEN = 256\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "DEVICE = 'cuda'\n",
    "NUM_EPOCHS = 75\n",
    "# DEVICE = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c2f340",
   "metadata": {},
   "source": [
    "## Utilites for Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c332bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to club together sequential operations\n",
    "def sequential_transforms(*transforms):\n",
    "    def func(txt_input):\n",
    "        for transform in transforms:\n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "    return func\n",
    "\n",
    "# function to add BOS/EOS and create tensor for input sequence indices\n",
    "def tensor_transform(token_ids: List[int]):\n",
    "    return torch.cat((torch.tensor([BOS_IDX]),\n",
    "                      torch.tensor(token_ids),\n",
    "                      torch.tensor([EOS_IDX])))\n",
    "\n",
    "# ``src`` and ``tgt`` language text transforms to convert raw strings into tensors indices\n",
    "text_transform = {}\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    text_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n",
    "                                               vocab_transform[ln], #Numericalization\n",
    "                                               tensor_transform) # Add BOS/EOS and create tensor\n",
    "\n",
    "\n",
    "# function to collate data samples into batch tensors\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src_sample, tgt_sample in batch:\n",
    "        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n",
    "        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
    "\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX, batch_first=True)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX, batch_first=True)\n",
    "    return src_batch, tgt_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cad2127",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7bc121b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36,057,347 total parameters.\n",
      "36,057,347 training parameters.\n",
      "Transformer(\n",
      "  (encoder): TransformerEncoder(\n",
      "    (embedding): Embedding(\n",
      "      (embed): Embedding(19293, 512)\n",
      "    )\n",
      "    (positional_encoding): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (layers): ModuleList(\n",
      "      (0-2): 3 x TransformerBlock(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (k): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (v): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (out): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (ffn): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (embedding): Embedding(\n",
      "      (embed): Embedding(10819, 512)\n",
      "    )\n",
      "    (postional_encoding): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (layers): ModuleList(\n",
      "      (0-2): 3 x DecoderBlock(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (k): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (v): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (out): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (transformer_block): TransformerBlock(\n",
      "          (attention): MultiHeadAttention(\n",
      "            (q): Linear(in_features=64, out_features=64, bias=True)\n",
      "            (k): Linear(in_features=64, out_features=64, bias=True)\n",
      "            (v): Linear(in_features=64, out_features=64, bias=True)\n",
      "            (out): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (ffn): Sequential(\n",
      "            (0): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          )\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fc): Linear(in_features=512, out_features=10819, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = transformer.Transformer(\n",
    "    embed_dim=EMB_SIZE,\n",
    "    src_vocab_size=SRC_VOCAB_SIZE,\n",
    "    tgt_vocab_size=TGT_VOCAB_SIZE,\n",
    "    seq_len=MAX_LEN,\n",
    "    num_layers=NUM_ENCODER_LAYERS,\n",
    "    n_heads=NHEAD,\n",
    "    device=DEVICE,\n",
    "    dropout=0.1\n",
    ").to(DEVICE)\n",
    "\n",
    "# Total parameters and trainable parameters.\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"{total_params:,} total parameters.\")\n",
    "total_trainable_params = sum(\n",
    "    p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"{total_trainable_params:,} training parameters.\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c25777a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for p in model.parameters():\n",
    "#     if p.dim() > 1:\n",
    "#         nn.init.xavier_uniform_(p)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a41f2318",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "def train_epoch(model, optimizer):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "\n",
    "    for src, tgt in train_dataloader:\n",
    "        # print(\" \".join(vocab_transform[SRC_LANGUAGE].lookup_tokens(list(src[0].cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\"))\n",
    "        # print(\" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt[0].cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\"))\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "        \n",
    "        tgt_input = tgt[:, :-1]\n",
    "\n",
    "        logits = model(src, tgt_input)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        tgt_out = tgt[:, 1:]\n",
    "        loss = loss_fn(logits.view(-1, TGT_VOCAB_SIZE), tgt_out.contiguous().view(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(list(train_dataloader))\n",
    "\n",
    "\n",
    "val_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "\n",
    "    for src, tgt in val_dataloader:\n",
    "        # print(\" \".join(vocab_transform[SRC_LANGUAGE].lookup_tokens(list(src[0].cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\"))\n",
    "        # print(\" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt[0].cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\"))\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "        \n",
    "        tgt_input = tgt[:, :-1]\n",
    "        \n",
    "        logits = model(src, tgt_input)\n",
    "\n",
    "        tgt_out = tgt[:, 1:]\n",
    "        loss = loss_fn(logits.view(-1, TGT_VOCAB_SIZE), tgt_out.contiguous().view(-1))\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(list(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7efaf99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train loss: 5.647, Val loss: 4.772, Epoch time = 62.767s\n",
      "Epoch: 2, Train loss: 4.518, Val loss: 4.161, Epoch time = 62.893s\n",
      "Epoch: 3, Train loss: 4.061, Val loss: 3.782, Epoch time = 64.410s\n",
      "Epoch: 4, Train loss: 3.760, Val loss: 3.537, Epoch time = 68.796s\n",
      "Epoch: 5, Train loss: 3.531, Val loss: 3.352, Epoch time = 73.837s\n",
      "Epoch: 6, Train loss: 3.348, Val loss: 3.203, Epoch time = 73.689s\n",
      "Epoch: 7, Train loss: 3.197, Val loss: 3.076, Epoch time = 73.617s\n",
      "Epoch: 8, Train loss: 3.067, Val loss: 2.971, Epoch time = 75.402s\n",
      "Epoch: 9, Train loss: 2.957, Val loss: 2.886, Epoch time = 76.924s\n",
      "Epoch: 10, Train loss: 2.860, Val loss: 2.812, Epoch time = 74.137s\n",
      "Epoch: 11, Train loss: 2.771, Val loss: 2.736, Epoch time = 77.777s\n",
      "Epoch: 12, Train loss: 2.695, Val loss: 2.684, Epoch time = 77.348s\n",
      "Epoch: 13, Train loss: 2.621, Val loss: 2.634, Epoch time = 77.682s\n",
      "Epoch: 14, Train loss: 2.555, Val loss: 2.572, Epoch time = 76.698s\n",
      "Epoch: 15, Train loss: 2.492, Val loss: 2.535, Epoch time = 76.692s\n",
      "Epoch: 16, Train loss: 2.437, Val loss: 2.497, Epoch time = 78.869s\n",
      "Epoch: 17, Train loss: 2.384, Val loss: 2.465, Epoch time = 78.999s\n",
      "Epoch: 18, Train loss: 2.334, Val loss: 2.432, Epoch time = 77.601s\n",
      "Epoch: 19, Train loss: 2.286, Val loss: 2.400, Epoch time = 77.561s\n",
      "Epoch: 20, Train loss: 2.240, Val loss: 2.365, Epoch time = 78.276s\n",
      "Epoch: 21, Train loss: 2.197, Val loss: 2.340, Epoch time = 76.430s\n",
      "Epoch: 22, Train loss: 2.157, Val loss: 2.325, Epoch time = 80.829s\n",
      "Epoch: 23, Train loss: 2.118, Val loss: 2.295, Epoch time = 75.880s\n",
      "Epoch: 24, Train loss: 2.080, Val loss: 2.286, Epoch time = 74.242s\n",
      "Epoch: 25, Train loss: 2.042, Val loss: 2.271, Epoch time = 74.180s\n",
      "Epoch: 26, Train loss: 2.010, Val loss: 2.240, Epoch time = 75.122s\n",
      "Epoch: 27, Train loss: 1.976, Val loss: 2.231, Epoch time = 73.360s\n",
      "Epoch: 28, Train loss: 1.945, Val loss: 2.217, Epoch time = 73.531s\n",
      "Epoch: 29, Train loss: 1.914, Val loss: 2.200, Epoch time = 74.432s\n",
      "Epoch: 30, Train loss: 1.885, Val loss: 2.173, Epoch time = 73.670s\n",
      "Epoch: 31, Train loss: 1.856, Val loss: 2.164, Epoch time = 73.143s\n",
      "Epoch: 32, Train loss: 1.827, Val loss: 2.150, Epoch time = 73.758s\n",
      "Epoch: 33, Train loss: 1.800, Val loss: 2.131, Epoch time = 74.064s\n",
      "Epoch: 34, Train loss: 1.773, Val loss: 2.136, Epoch time = 73.871s\n",
      "Epoch: 35, Train loss: 1.746, Val loss: 2.119, Epoch time = 73.595s\n",
      "Epoch: 36, Train loss: 1.723, Val loss: 2.103, Epoch time = 73.469s\n",
      "Epoch: 37, Train loss: 1.698, Val loss: 2.098, Epoch time = 74.226s\n",
      "Epoch: 38, Train loss: 1.675, Val loss: 2.089, Epoch time = 74.279s\n",
      "Epoch: 39, Train loss: 1.650, Val loss: 2.084, Epoch time = 72.311s\n",
      "Epoch: 40, Train loss: 1.628, Val loss: 2.077, Epoch time = 75.686s\n",
      "Epoch: 41, Train loss: 1.608, Val loss: 2.077, Epoch time = 76.753s\n",
      "Epoch: 42, Train loss: 1.583, Val loss: 2.048, Epoch time = 76.733s\n",
      "Epoch: 43, Train loss: 1.564, Val loss: 2.054, Epoch time = 77.611s\n",
      "Epoch: 44, Train loss: 1.544, Val loss: 2.052, Epoch time = 77.524s\n",
      "Epoch: 45, Train loss: 1.525, Val loss: 2.042, Epoch time = 76.192s\n",
      "Epoch: 46, Train loss: 1.505, Val loss: 2.044, Epoch time = 76.377s\n",
      "Epoch: 47, Train loss: 1.484, Val loss: 2.050, Epoch time = 76.434s\n",
      "Epoch: 48, Train loss: 1.466, Val loss: 2.022, Epoch time = 76.524s\n",
      "Epoch: 49, Train loss: 1.447, Val loss: 2.029, Epoch time = 77.353s\n",
      "Epoch: 50, Train loss: 1.430, Val loss: 2.029, Epoch time = 78.476s\n",
      "Epoch: 51, Train loss: 1.412, Val loss: 2.025, Epoch time = 76.221s\n",
      "Epoch: 52, Train loss: 1.395, Val loss: 2.025, Epoch time = 75.718s\n",
      "Epoch: 53, Train loss: 1.379, Val loss: 2.018, Epoch time = 75.785s\n",
      "Epoch: 54, Train loss: 1.364, Val loss: 2.021, Epoch time = 73.614s\n",
      "Epoch: 55, Train loss: 1.345, Val loss: 2.022, Epoch time = 74.725s\n",
      "Epoch: 56, Train loss: 1.331, Val loss: 2.031, Epoch time = 74.119s\n",
      "Epoch: 57, Train loss: 1.315, Val loss: 2.026, Epoch time = 74.359s\n",
      "Epoch: 58, Train loss: 1.300, Val loss: 2.018, Epoch time = 76.490s\n",
      "Epoch: 59, Train loss: 1.287, Val loss: 2.038, Epoch time = 76.911s\n",
      "Epoch: 60, Train loss: 1.269, Val loss: 2.025, Epoch time = 77.281s\n",
      "Epoch: 61, Train loss: 1.256, Val loss: 2.017, Epoch time = 77.489s\n",
      "Epoch: 62, Train loss: 1.244, Val loss: 1.999, Epoch time = 77.450s\n",
      "Epoch: 63, Train loss: 1.228, Val loss: 2.006, Epoch time = 80.312s\n",
      "Epoch: 64, Train loss: 1.215, Val loss: 2.003, Epoch time = 75.497s\n",
      "Epoch: 65, Train loss: 1.203, Val loss: 2.006, Epoch time = 75.714s\n",
      "Epoch: 66, Train loss: 1.189, Val loss: 1.995, Epoch time = 75.881s\n",
      "Epoch: 67, Train loss: 1.175, Val loss: 1.992, Epoch time = 80.483s\n",
      "Epoch: 68, Train loss: 1.163, Val loss: 2.002, Epoch time = 78.347s\n",
      "Epoch: 69, Train loss: 1.149, Val loss: 2.008, Epoch time = 75.225s\n",
      "Epoch: 70, Train loss: 1.138, Val loss: 1.993, Epoch time = 76.999s\n",
      "Epoch: 71, Train loss: 1.127, Val loss: 2.000, Epoch time = 76.063s\n",
      "Epoch: 72, Train loss: 1.115, Val loss: 2.002, Epoch time = 76.571s\n",
      "Epoch: 73, Train loss: 1.103, Val loss: 2.001, Epoch time = 75.552s\n",
      "Epoch: 74, Train loss: 1.091, Val loss: 2.002, Epoch time = 76.850s\n",
      "Epoch: 75, Train loss: 1.079, Val loss: 1.999, Epoch time = 76.244s\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = timer()\n",
    "    train_loss = train_epoch(model, optimizer)\n",
    "    end_time = timer()\n",
    "    val_loss = evaluate(model)\n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88e5fc54-9ff3-4df2-8c15-c1f257fe7408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs('outputs/translation_custom_dataloader', exist_ok=True)\n",
    "torch.save(model, 'outputs/translation_custom_dataloader/model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317dbf60-1a73-4de5-abc1-b92d0f750f40",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da73a6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(translate(model, \"Eine Gruppe von Menschen steht vor einem Iglu .\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4651a7e9-9cdf-4a0c-b89b-3d9cf8fa9d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from attention.transformer import TransformerDecoder, TransformerEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82069238-8a62-4b4d-a2d3-196e196db258",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('outputs/translation_custom_dataloader/model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9a722e9-879e-4c94-91ee-230b6bcc54a7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer(\n",
      "  (encoder): TransformerEncoder(\n",
      "    (embedding): Embedding(\n",
      "      (embed): Embedding(19293, 512)\n",
      "    )\n",
      "    (positional_encoding): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (layers): ModuleList(\n",
      "      (0-2): 3 x TransformerBlock(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (k): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (v): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (out): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (ffn): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (embedding): Embedding(\n",
      "      (embed): Embedding(10819, 512)\n",
      "    )\n",
      "    (postional_encoding): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (layers): ModuleList(\n",
      "      (0-2): 3 x DecoderBlock(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (k): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (v): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (out): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (transformer_block): TransformerBlock(\n",
      "          (attention): MultiHeadAttention(\n",
      "            (q): Linear(in_features=64, out_features=64, bias=True)\n",
      "            (k): Linear(in_features=64, out_features=64, bias=True)\n",
      "            (v): Linear(in_features=64, out_features=64, bias=True)\n",
      "            (out): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (ffn): Sequential(\n",
      "            (0): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          )\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fc): Linear(in_features=512, out_features=10819, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "635dc734-e284-428a-89ee-9a33505d49e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tgt_mask(tgt, pad_token_id=1):\n",
    "    \"\"\"\n",
    "    :param tgt: Target sequence.\n",
    "    Returns:\n",
    "        tgt_mask: Target mask.\n",
    "    \"\"\"\n",
    "    batch_size = tgt.shape[0]\n",
    "    device = tgt.device\n",
    "\n",
    "    # Same as src_mask but we additionally want to mask tokens from looking forward into the future tokens\n",
    "    # Note: wherever the mask value is true we want to attend to that token, otherwise we mask (ignore) it.\n",
    "    sequence_length = tgt.shape[1]  # trg_token_ids shape = (B, T) where T max trg token-sequence length\n",
    "    trg_padding_mask = (tgt != pad_token_id).view(batch_size, 1, 1, -1)  # shape = (B, 1, 1, T)\n",
    "    trg_no_look_forward_mask = torch.triu(torch.ones((1, 1, sequence_length, sequence_length), device=device) == 1).transpose(2, 3)\n",
    "\n",
    "    # logic AND operation (both padding mask and no-look-forward must be true to attend to a certain target token)\n",
    "    tgt_mask = trg_padding_mask & trg_no_look_forward_mask  # final shape = (B, 1, T, T)\n",
    "    return tgt_mask\n",
    "    \n",
    "def make_src_mask(src, pad_token_id=1):\n",
    "    \"\"\"\n",
    "    :param src: Source sequence.\n",
    "\n",
    "    Returns:\n",
    "        src_mask: Source mask.\n",
    "    \"\"\"\n",
    "    batch_size = src.shape[0]\n",
    "\n",
    "    # src_mask shape = (B, 1, 1, S) check out attention function in transformer_model.py where masks are applied\n",
    "    # src_mask only masks pad tokens as we want to ignore their representations (no information in there...)\n",
    "    src_mask = (src != pad_token_id).view(batch_size, 1, 1, -1)\n",
    "    return src_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5197023d-7bf1-47bb-a53c-c05813c3d821",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = TransformerDecoder(\n",
    "            TGT_VOCAB_SIZE,\n",
    "            EMB_SIZE,\n",
    "            MAX_LEN,\n",
    "            NUM_ENCODER_LAYERS,\n",
    "            expansion_factor=4,\n",
    "            n_heads=NHEAD\n",
    "        ).to(DEVICE).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f1d6df0-244d-4eb4-980c-1afeb5ec0f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.load_state_dict(model.decoder.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d807ba81-35e0-4d6e-be10-49dff824527c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = TransformerEncoder(\n",
    "            MAX_LEN,\n",
    "            SRC_VOCAB_SIZE,\n",
    "            EMB_SIZE,\n",
    "            NUM_ENCODER_LAYERS,\n",
    "            expansion_factor=4,\n",
    "            n_heads=NHEAD\n",
    "        ).to(DEVICE).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e06a966-864d-409e-b665-34ed890acfd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.load_state_dict(model.encoder.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe75f44f-97d7-4aac-8552-b47f61392445",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder): TransformerEncoder(\n",
       "    (embedding): Embedding(\n",
       "      (embed): Embedding(19293, 512)\n",
       "    )\n",
       "    (positional_encoding): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0-2): 3 x TransformerBlock(\n",
       "        (attention): MultiHeadAttention(\n",
       "          (q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (k): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (v): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (out): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): TransformerDecoder(\n",
       "    (embedding): Embedding(\n",
       "      (embed): Embedding(10819, 512)\n",
       "    )\n",
       "    (postional_encoding): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0-2): 3 x DecoderBlock(\n",
       "        (attention): MultiHeadAttention(\n",
       "          (q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (k): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (v): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (out): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (transformer_block): TransformerBlock(\n",
       "          (attention): MultiHeadAttention(\n",
       "            (q): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (k): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (v): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (out): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (ffn): Sequential(\n",
       "            (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fc): Linear(in_features=512, out_features=10819, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0db54237-1e21-47ec-b4f1-13ac8522a1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(src, tgt):\n",
    "    \"\"\"\n",
    "    :param src: Encoder input\n",
    "    :param tgt: Decoder input\n",
    "\n",
    "    Returns:\n",
    "        out_labels: Final prediction sequence\n",
    "    \"\"\"\n",
    "    tgt_mask = make_tgt_mask(tgt).to(DEVICE)\n",
    "    src_mask = make_src_mask(src).to(DEVICE)\n",
    "    enc_out = encoder(src)\n",
    "    out_labels = []\n",
    "    batch_size, seq_len = src.shape[0], src.shape[1]\n",
    "    out = tgt\n",
    "    with torch.no_grad():\n",
    "        for i in range(seq_len):\n",
    "            if i != 0:\n",
    "                tgt = torch.tensor(out_labels, dtype=torch.long).unsqueeze(0).to(DEVICE)\n",
    "                # print(tgt)\n",
    "                out = decoder(torch.tensor(tgt).to(DEVICE), enc_out, src_mask, tgt_mask)\n",
    "            else:\n",
    "                out = decoder(out, enc_out, src_mask, tgt_mask)\n",
    "            out = out.reshape(-1, out.shape[-1])\n",
    "            num_of_trg_tokens = len(tgt[0])\n",
    "            out = out[num_of_trg_tokens-1::num_of_trg_tokens]\n",
    "            out = torch.argmax(out, dim=-1)\n",
    "            out_labels.append(out.item())\n",
    "            out = torch.unsqueeze(out, 0)\n",
    "        return out_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac17ace8-a2ad-4ebd-a1b0-0d982612b98b",
   "metadata": {},
   "source": [
    "### Some Test Samples\n",
    "\n",
    "Top - English\\\n",
    "Bottom - German\n",
    "\n",
    "A man in an orange hat starring at something.\\\n",
    "Ein Mann mit einem orangefarbenen Hut, der etwas anstarrt.\n",
    "\n",
    "A Boston Terrier is running on lush green grass in front of a white fence.\\\n",
    "Ein Boston Terrier läuft über saftig-grünes Gras vor einem weißen Zaun.\n",
    "\n",
    "A girl in karate uniform breaking a stick with a front kick.\\\n",
    "Ein Mädchen in einem Karateanzug bricht einen Stock mit einem Tritt.\n",
    "\n",
    "Five people wearing winter jackets and helmets stand in the snow, with snowmobiles in the background...\\\n",
    "Fünf Leute in Winterjacken und mit Helmen stehen im Schnee mit Schneemobilen im Hintergrund.\n",
    "\n",
    "People are fixing the roof of a house.\\\n",
    "Leute Reparieren das Dach eines Hauses.\n",
    "\n",
    "A man in light colored clothing photographs a group of men wearing dark suits and hats standing arou...\\\n",
    "Ein hell gekleideter Mann fotografiert eine Gruppe von Männern in dunklen Anzügen und mit Hüten, die...\n",
    "\n",
    "A group of people standing in front of an igloo.\\\n",
    "Eine Gruppe von Menschen steht vor einem Iglu.\n",
    "\n",
    "A boy in a red uniform is attempting to avoid getting out at home plate, while the catcher in the bl...\\\n",
    "Ein Junge in einem roten Trikot versucht, die Home Base zu erreichen, während der Catcher im blauen ...\n",
    "\n",
    "A guy works on a building.\\\n",
    "Ein Typ arbeitet an einem Gebäude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2c060e91-035d-48f8-a6bc-dee1300960f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Five people in winter jackets and helmets are standing in the snow with ski poles in the\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_247/2588931828.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  out = decoder(torch.tensor(tgt).to(DEVICE), enc_out, src_mask, tgt_mask)\n"
     ]
    }
   ],
   "source": [
    "# Full-stops are important for the model to perform well.\n",
    "src_sentence = \"Fünf Leute in Winterjacken und mit Helmen stehen im Schnee mit Schneemobilen im Hintergrund.\"\n",
    "start_symbol = BOS_IDX\n",
    "src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n",
    "num_tokens = src.shape[0]\n",
    "src = src.to(DEVICE)\n",
    "ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "out = decode(torch.ravel(src).unsqueeze(0), ys)\n",
    "print(\" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(out))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaec6c2-b154-47fb-bcab-74d0b6468b20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9b3489-942c-4aa7-bfe7-224b73f45ebb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
