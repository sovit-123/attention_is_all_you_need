{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2244ec4a",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Find small single text files for **Language Modeling** experiements here ⬇️\n",
    "\n",
    "https://www.kaggle.com/datasets/sovitrath/text-generation-language-modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ab67365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import requests\n",
    "import os\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import tiktoken\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from utils.text_gen import get_batch, train, validate, NLPDataset\n",
    "from collections import Counter\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch import Tensor\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from attention.transformer_linear_decoder import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c113ac09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed.\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67a64d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu May 25 22:42:28 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.182.03   Driver Version: 470.182.03   CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0  On |                  N/A |\r\n",
      "| 30%   48C    P8    29W / 370W |    417MiB / 10009MiB |     35%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      1265      G   /usr/lib/xorg/Xorg                 35MiB |\r\n",
      "|    0   N/A  N/A      1862      G   /usr/lib/xorg/Xorg                171MiB |\r\n",
      "|    0   N/A  N/A      1998      G   /usr/bin/gnome-shell               36MiB |\r\n",
      "|    0   N/A  N/A      3697      G   ...309105646604474703,262144      132MiB |\r\n",
      "|    0   N/A  N/A     21367      G   ...RendererForSitePerProcess       26MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb8a3761",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = 'outputs/text_gen_simple_dec_alice' \n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f536148c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alice.txt']\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = os.path.join('../../input', 'alice_short_story')\n",
    "train_file = os.listdir(dataset_dir)\n",
    "print(train_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c2fac3",
   "metadata": {},
   "source": [
    "## Prepare the Dataset\n",
    "Let's find the longest review in the entire training set. As this will also contain the <br> tags, we will take the average of that.\n",
    "\n",
    "We will pad the smaller sentences to this average length and truncate the longer sentences to the average length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0eb7e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words (possibly, without tokenization): 1243 words\n"
     ]
    }
   ],
   "source": [
    "def find_longest_length(text_file_paths):\n",
    "    \"\"\"\n",
    "    Find the longest review length in the entire training set. \n",
    "\n",
    "    :param text_file_paths: List, containing all the text file paths.\n",
    "\n",
    "    Returns:\n",
    "        max_len: Longest review length.\n",
    "    \"\"\"\n",
    "    max_length = 0\n",
    "    for path in text_file_paths:\n",
    "        with open(path, 'r') as f:\n",
    "            text = f.read()\n",
    "            corpus = [\n",
    "                word for word in text.split()\n",
    "            ]\n",
    "        if len(corpus) > max_length:\n",
    "            max_length = len(corpus)\n",
    "    return max_length\n",
    "\n",
    "\n",
    "file_paths = []\n",
    "file_paths.extend(glob.glob(os.path.join(\n",
    "    dataset_dir, '*.txt'\n",
    ")))\n",
    "longest_sentence_length = find_longest_length(file_paths)\n",
    "print(f\"Total words (possibly, without tokenization): {longest_sentence_length} words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67f94dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of words to generate in a sentence.\n",
    "SEQUENCE_LENGTH = 128\n",
    "NUM_WORDS = 50304  # Vocabulary size.\n",
    "\n",
    "# Batch size.\n",
    "BATCH_SIZE = 1\n",
    "VALID_SPLIT = 0.1\n",
    "EPOCHS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dcefd8",
   "metadata": {},
   "source": [
    "### Helper Functions \n",
    "\n",
    "A few helper functions to prepare the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5beabba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_word_frequency(\n",
    "    text_file_paths, num_files, most_common=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a list of tuples of the following format,\n",
    "    [('ho', 2), ('hello', 1), (\"let's\", 1), ('go', 1)]\n",
    "    where the number represents the frequency of occurance of \n",
    "    the word in the entire dataset.\n",
    "\n",
    "    :param text_file_paths: List, containing all the text file paths.\n",
    "    :param most_common: Return these many top words from the dataset.\n",
    "        If `most_common` is None, return all. If `most_common` is 3,\n",
    "        returns the top 3 tuple pairs in the list.\n",
    "\n",
    "    Returns:\n",
    "        sorted_words: A list of tuple containing each word and it's\n",
    "        frequency of the format ('ho', 2), ('hello', 1), ...]\n",
    "    \"\"\"\n",
    "    # Add all the words in the entire dataset to `corpus` list.\n",
    "    corpus = []\n",
    "    for i, path in enumerate(text_file_paths):\n",
    "        if i+1 == num_files:\n",
    "            break\n",
    "        with open(path, 'r') as f:\n",
    "            text = f.read()\n",
    "            # Remove <br> tags.\n",
    "            text = re.sub('<[^>]+>+', '', text)\n",
    "            corpus.extend([\n",
    "                word for word in text.split()\n",
    "            ])\n",
    "    count_words = Counter(corpus)\n",
    "    # Create a dictionary with the most common word in the corpus \n",
    "    # at the beginning.\n",
    "    # `word_frequency` will be like \n",
    "    word_frequency = count_words.most_common(n=most_common) # Returns all as n is `None`.\n",
    "    return word_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3175f635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2int(input_words, num_words):\n",
    "    \"\"\"\n",
    "    Create a dictionary of word to integer mapping for each unique word.\n",
    "\n",
    "    :param input_words: A list of tuples containing the words and \n",
    "        theiry frequency. Should be of the following format,\n",
    "        [('ho', 2), ('hello', 1), (\"let's\", 1), ('go', 1)]\n",
    "    :param num_words: Number of words to use from the `input_words` list \n",
    "        to create the mapping. If -1, use all words in the dataset.\n",
    "\n",
    "    Returns:\n",
    "        int_mapping: A dictionary of word and a integer mapping as \n",
    "            key-value pair. Example, {'Hello,': 1, 'the': 2, 'let': 3}\n",
    "    \"\"\"\n",
    "\n",
    "    if num_words > -1:\n",
    "        int_mapping = {\n",
    "            w:i+1 for i, (w, c) in enumerate(input_words) \\\n",
    "                if i <= num_words - 1 # -1 to avoid getting (num_words + 1) integer mapping.\n",
    "        }\n",
    "    else:\n",
    "        int_mapping = {w:i+1 for i, (w, c) in enumerate(input_words)}\n",
    "    return int_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c839d68",
   "metadata": {},
   "source": [
    "### Tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d56e82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = tiktoken.encoding_for_model(\"gpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a58440",
   "metadata": {},
   "source": [
    "## Prepare PyTorch Datasets and Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ac014e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = os.path.join(dataset_dir, train_file[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c29007b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_inst = NLPDataset(file_paths, enc)\n",
    "dataset = dataset_inst.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1e7d42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: torch.Size([1536])\n",
      "Number of unique tokens: 618\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total tokens: {dataset.shape}\")\n",
    "print(f\"Number of unique tokens: {len(np.unique(dataset))}\")\n",
    "# print(f\"Number of chosen words to act as vocabulary (tokens): {len(int_mapping)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9def8720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 1383\n",
      "Number of validation samples: 153\n"
     ]
    }
   ],
   "source": [
    "dataset_size = len(dataset)\n",
    "# Calculate the validation dataset size.\n",
    "valid_size = int(VALID_SPLIT*dataset_size)\n",
    "# Radomize the data indices.\n",
    "indices = torch.randperm(len(dataset)).tolist()\n",
    "# Training and validation sets.\n",
    "dataset_train = dataset[:-valid_size]\n",
    "dataset_valid = dataset[-valid_size:]\n",
    "\n",
    "# dataset_valid = NLPClassificationDataset()\n",
    "print(f\"Number of training samples: {len(dataset_train)}\")\n",
    "print(f\"Number of validation samples: {len(dataset_valid)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0361eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1383\n",
      "153\n"
     ]
    }
   ],
   "source": [
    "print(dataset_train.size(0))\n",
    "print(dataset_valid.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "afa95d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9e45605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, batch in enumerate(dataset_train):\n",
    "#     inp, tgt = get_batch('train')\n",
    "#     print(inp)\n",
    "#     print(tgt)\n",
    "#     inp_words = ''\n",
    "#     tgt_words = ''\n",
    "#     inp = inp[0].cpu().numpy()\n",
    "#     tgt = tgt[0].cpu().numpy()\n",
    "#     print(len(inp))\n",
    "#     print(len(tgt))\n",
    "#     for idx in inp:\n",
    "#         inp_words += ' ' + int2word_train[idx]\n",
    "#     print(inp_words)\n",
    "#     print('*'*50)\n",
    "#     for idx in tgt:\n",
    "#         tgt_words += ' ' + int2word_train[idx]\n",
    "#     print(tgt_words)\n",
    "#     if i == 2:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66743536",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "513af03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(\n",
    "    embed_dim=512, \n",
    "    src_vocab_size=NUM_WORDS, \n",
    "    seq_len=SEQUENCE_LENGTH,\n",
    "    num_layers=6, \n",
    "    expansion_factor=4, \n",
    "    n_heads=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5621ac84",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5508f234",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b96fd55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer(\n",
      "  (encoder): TransformerEncoder(\n",
      "    (embedding): Embedding(\n",
      "      (embed): Embedding(50304, 512)\n",
      "    )\n",
      "    (positional_encoding): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerBlock(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (k): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (v): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (out): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (ffn): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (1): TransformerBlock(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (k): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (v): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (out): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (ffn): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (2): TransformerBlock(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (k): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (v): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (out): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (ffn): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (3): TransformerBlock(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (k): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (v): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (out): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (ffn): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (4): TransformerBlock(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (k): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (v): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (out): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (ffn): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (5): TransformerBlock(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (k): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (v): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (out): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (ffn): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Linear(in_features=512, out_features=50304, bias=True)\n",
      ")\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "65,822,976 total parameters.\n",
      "65,822,976 training parameters.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(), \n",
    "    lr=0.0001,\n",
    ")\n",
    "\n",
    "# StepLR every specific number of epochs.\n",
    "scheduler = StepLR(\n",
    "    optimizer, \n",
    "    step_size=5, \n",
    "    gamma=0.5,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Total parameters and trainable parameters.\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"{total_params:,} total parameters.\")\n",
    "total_trainable_params = sum(\n",
    "    p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"{total_trainable_params:,} training parameters.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "999052b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Epoch 1 of 1\n",
      "Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c840694dd1e4bad810a29f564e55537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29ebee7b1a1b4da385f360ba11e2c208",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.339359716935592\n",
      "Validation loss: 9.276801586151123\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "epochs = EPOCHS\n",
    "# Lists to keep track of losses and accuracies.\n",
    "train_loss, valid_loss = [], []\n",
    "train_acc, valid_acc = [], []\n",
    "# Start the training.\n",
    "for epoch in range(epochs):\n",
    "    print(f\"[INFO]: Epoch {epoch+1} of {epochs}\")\n",
    "    train_epoch_loss = train(\n",
    "        model, \n",
    "        dataset_train, \n",
    "        optimizer, \n",
    "        criterion,\n",
    "        SEQUENCE_LENGTH,\n",
    "        NUM_WORDS,\n",
    "        BATCH_SIZE,\n",
    "        device\n",
    "    )\n",
    "    valid_epoch_loss = validate(\n",
    "        model, \n",
    "        dataset_valid,  \n",
    "        criterion,\n",
    "        SEQUENCE_LENGTH,\n",
    "        NUM_WORDS,\n",
    "        BATCH_SIZE,\n",
    "        device\n",
    "    )\n",
    "    train_loss.append(train_epoch_loss)\n",
    "    valid_loss.append(valid_epoch_loss)\n",
    "    print(f\"Training loss: {train_epoch_loss}\")\n",
    "    print(f\"Validation loss: {valid_epoch_loss}\")\n",
    "\n",
    "    # Save model.\n",
    "    torch.save(\n",
    "        model, os.path.join(CHECKPOINT_DIR, 'model.pth')\n",
    "    )\n",
    "    print('-'*50)\n",
    "#     if epoch + 1 <= 32:\n",
    "#         scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56e504f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plots(train_acc, valid_acc, train_loss, valid_loss):\n",
    "    \"\"\"\n",
    "    Function to save the loss and accuracy plots to disk.\n",
    "    \"\"\"\n",
    "    plt.show()\n",
    "    # Loss plots.\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot(\n",
    "        train_loss, color='blue', linestyle='-', \n",
    "        label='train loss'\n",
    "    )\n",
    "    plt.plot(\n",
    "        valid_loss, color='red', linestyle='-', \n",
    "        label='validataion loss'\n",
    "    )\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "#     plt.savefig(f\"../outputs/loss.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5e4eced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_plots(train_acc, valid_acc, train_loss, valid_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee6468b",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c3810a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = torch.load(\n",
    "    os.path.join(CHECKPOINT_DIR, 'model.pth')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01bc10b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loss = validate(\n",
    "#     trained_model, \n",
    "#     dataset_test,  \n",
    "#     criterion, \n",
    "#     device\n",
    "# )\n",
    "\n",
    "# print(f\"Test loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86e1a2f",
   "metadata": {},
   "source": [
    "## Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f269eb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_int_vector(enc, text):\n",
    "        \"\"\"\n",
    "        Assign an integer to each word and return the integers in a list.\n",
    "        \"\"\"\n",
    "        return enc.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f9e7817",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = tiktoken.encoding_for_model(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c11d2a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_next(predictions, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Implement variable-temperature sampling from a probability\n",
    "    distribution.\n",
    "    \"\"\"\n",
    "    predictions = predictions.squeeze(0)[-1, :] / temperature\n",
    "    predictions = predictions.exp().cpu()\n",
    "    next_token = torch.multinomial(predictions, num_samples=1)\n",
    "    return int(next_token[0].cpu())\n",
    "    \n",
    "\n",
    "def text_generator(sentence, generate_length):\n",
    "    trained_model.eval()\n",
    "    temperatures = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0] \n",
    "    num_tokens = len(sentence)\n",
    "    for temeperature in temperatures:\n",
    "        sample = sentence\n",
    "        print(f\"GENERATED SENTENCE WITH TEMPERATURE {temeperature}\")\n",
    "        for i in range(generate_length):\n",
    "            int_vector = return_int_vector(enc, sample)\n",
    "            input_tensor = torch.tensor(int_vector, dtype=torch.int32)\n",
    "            input_tensor = input_tensor.unsqueeze(0).to(device)\n",
    "            with torch.no_grad():\n",
    "                predictions = trained_model(input_tensor)\n",
    "            next_token = sample_next(predictions)\n",
    "#             if next_token != 0: # Ignore <pad> index. Final sentence may be shorter.\n",
    "            sample += ' ' + enc.decode([next_token])\n",
    "        print(sample)\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2afbe177",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d418dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"Alice was a curious and imaginative young girl who lived in a quiet village.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9822d8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT: Alice was a curious and imaginative young girl who lived in a quiet village.\n",
      "GENERATED SENTENCE WITH TEMPERATURE 0.1\n",
      "Alice was a curious and imaginative young girl who lived in a quiet village. ilk  Twisted  binge steel served vs  Soy  leaflets \\/  binaries pedia  Xin ++;  ger aying  Gujar Around  off  Alice  Danish ieving  Hive  remed VEN  Facilities 333  Heb Sav  1983  pasta division  correction  Romeo  contrace  Athens  brew  Eminem  carbs  sacks アル ,  ad PAC  prostitute  Harbor  forever  physicist  indefinitely  Freedom  argue  QC 0000000000000000  null  names  darkness oche  ori  Tomato iesel  evangelical  Blasio URR  Variant  hitherto  strand  WhatsApp  the  NEED  CAD  Sahara umin  Guam  286  Horse  sour  communicate  Big  videot  and  calorie  Mim  injected  farmland  Julian Az  Georgia  Elena  debunk  dough  exh  Pumpkin movie  basket  policing  trophy liberal  pad  anthropology  fest ーテ intage  Ame  Kelley  fitness  microbiota ciation  the  neuronal  tuning icates  Miracle  splendid  970 .  Strauss ilies izons SK  spin  Chaff  organize  extremes  399  penal  implication  corrid oufl  HOW\n",
      "\n",
      "\n",
      "GENERATED SENTENCE WITH TEMPERATURE 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "thread '<unnamed>' panicked at 'no entry found for key', src/lib.rs:201:37\n",
      "note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\n"
     ]
    },
    {
     "ename": "PanicException",
     "evalue": "no entry found for key",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPanicException\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m sentences:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPROMPT: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msentence\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mtext_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerate_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m############\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36mtext_generator\u001b[0;34m(sentence, generate_length)\u001b[0m\n\u001b[1;32m     25\u001b[0m             next_token \u001b[38;5;241m=\u001b[39m sample_next(predictions)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m#             if next_token != 0: # Ignore <pad> index. Final sentence may be shorter.\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m             sample \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[43menc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnext_token\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;28mprint\u001b[39m(sample)\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.9/site-packages/tiktoken/core.py:254\u001b[0m, in \u001b[0;36mEncoding.decode\u001b[0;34m(self, tokens, errors)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, tokens: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m], errors: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;124;03m\"\"\"Decodes a list of tokens into a string.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \n\u001b[1;32m    245\u001b[0m \u001b[38;5;124;03m    WARNING: the default behaviour of this function is lossy, since decoded bytes are not\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_core_bpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m, errors\u001b[38;5;241m=\u001b[39merrors)\n",
      "\u001b[0;31mPanicException\u001b[0m: no entry found for key"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    print(f\"PROMPT: {sentence}\")\n",
    "    text_generator(sentence, generate_length)\n",
    "    print('\\n############\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c16e047",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ace2233",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
