{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7eaf129",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Find small single text files for **Language Modeling** experiements here ⬇️\n",
    "\n",
    "https://www.kaggle.com/datasets/sovitrath/text-generation-language-modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ab67365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import tiktoken\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from utils.text_gen import get_batch, train_step, val_step, NLPDataset\n",
    "from collections import Counter\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c113ac09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed.\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67a64d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Dec  1 16:47:40 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1060        Off | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   66C    P0              27W /  78W |    702MiB /  6144MiB |      1%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1253      G   /usr/lib/xorg/Xorg                           45MiB |\n",
      "|    0   N/A  N/A      1797      G   /usr/lib/xorg/Xorg                          280MiB |\n",
      "|    0   N/A  N/A      1972      G   /usr/bin/gnome-shell                         50MiB |\n",
      "|    0   N/A  N/A      4101      G   ...,WinRetrieveSuggestionsOnlyOnDemand       58MiB |\n",
      "|    0   N/A  N/A      4259    C+G   ...7498978,13360403517688655995,262144      254MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb8a3761",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = 'outputs/text_gen_simple' \n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f536148c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['file.txt']\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = os.path.join('data/simple_data/simple1/')\n",
    "train_file = os.listdir(dataset_dir)\n",
    "print(train_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c2fac3",
   "metadata": {},
   "source": [
    "## Prepare the Dataset\n",
    "Let's find the longest review in the entire training set. As this will also contain the <br> tags, we will take the average of that.\n",
    "\n",
    "We will pad the smaller sentences to this average length and truncate the longer sentences to the average length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0eb7e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words (possibly, without tokenization): 525 words\n"
     ]
    }
   ],
   "source": [
    "def find_longest_length(text_file_paths):\n",
    "    \"\"\"\n",
    "    Find the longest review length in the entire training set. \n",
    "\n",
    "    :param text_file_paths: List, containing all the text file paths.\n",
    "\n",
    "    Returns:\n",
    "        max_len: Longest review length.\n",
    "    \"\"\"\n",
    "    max_length = 0\n",
    "    for path in text_file_paths:\n",
    "        with open(path, 'r') as f:\n",
    "            text = f.read()\n",
    "            corpus = [\n",
    "                word for word in text.split()\n",
    "            ]\n",
    "        if len(corpus) > max_length:\n",
    "            max_length = len(corpus)\n",
    "    return max_length\n",
    "\n",
    "\n",
    "file_paths = []\n",
    "file_paths.extend(glob.glob(os.path.join(\n",
    "    dataset_dir, '*.txt'\n",
    ")))\n",
    "longest_sentence_length = find_longest_length(file_paths)\n",
    "print(f\"Total words (possibly, without tokenization): {longest_sentence_length} words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67f94dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of words to generate in a sentence.\n",
    "SEQUENCE_LENGTH = 100\n",
    "# NUM_WORDS = 50257  # Vocabulary size.\n",
    "NUM_WORDS = 50257\n",
    "\n",
    "# Batch size.\n",
    "BATCH_SIZE = 16\n",
    "VALID_SPLIT = 0.2\n",
    "MAX_ITERS = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dcefd8",
   "metadata": {},
   "source": [
    "### Helper Functions \n",
    "\n",
    "A few helper functions to prepare the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5beabba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_word_frequency(\n",
    "    text_file_paths, num_files, most_common=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a list of tuples of the following format,\n",
    "    [('ho', 2), ('hello', 1), (\"let's\", 1), ('go', 1)]\n",
    "    where the number represents the frequency of occurance of \n",
    "    the word in the entire dataset.\n",
    "\n",
    "    :param text_file_paths: List, containing all the text file paths.\n",
    "    :param most_common: Return these many top words from the dataset.\n",
    "        If `most_common` is None, return all. If `most_common` is 3,\n",
    "        returns the top 3 tuple pairs in the list.\n",
    "\n",
    "    Returns:\n",
    "        sorted_words: A list of tuple containing each word and it's\n",
    "        frequency of the format ('ho', 2), ('hello', 1), ...]\n",
    "    \"\"\"\n",
    "    # Add all the words in the entire dataset to `corpus` list.\n",
    "    corpus = []\n",
    "    for i, path in enumerate(text_file_paths):\n",
    "        if i+1 == num_files:\n",
    "            break\n",
    "        with open(path, 'r') as f:\n",
    "            text = f.read()\n",
    "            # Remove <br> tags.\n",
    "            text = re.sub('<[^>]+>+', '', text)\n",
    "            corpus.extend([\n",
    "                word for word in text.split()\n",
    "            ])\n",
    "    count_words = Counter(corpus)\n",
    "    # Create a dictionary with the most common word in the corpus \n",
    "    # at the beginning.\n",
    "    # `word_frequency` will be like \n",
    "    word_frequency = count_words.most_common(n=most_common) # Returns all as n is `None`.\n",
    "    return word_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3175f635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2int(input_words, num_words):\n",
    "    \"\"\"\n",
    "    Create a dictionary of word to integer mapping for each unique word.\n",
    "\n",
    "    :param input_words: A list of tuples containing the words and \n",
    "        theiry frequency. Should be of the following format,\n",
    "        [('ho', 2), ('hello', 1), (\"let's\", 1), ('go', 1)]\n",
    "    :param num_words: Number of words to use from the `input_words` list \n",
    "        to create the mapping. If -1, use all words in the dataset.\n",
    "\n",
    "    Returns:\n",
    "        int_mapping: A dictionary of word and a integer mapping as \n",
    "            key-value pair. Example, {'Hello,': 1, 'the': 2, 'let': 3}\n",
    "    \"\"\"\n",
    "\n",
    "    if num_words > -1:\n",
    "        int_mapping = {\n",
    "            w:i+1 for i, (w, c) in enumerate(input_words) \\\n",
    "                if i <= num_words - 1 # -1 to avoid getting (num_words + 1) integer mapping.\n",
    "        }\n",
    "    else:\n",
    "        int_mapping = {w:i+1 for i, (w, c) in enumerate(input_words)}\n",
    "    return int_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c839d68",
   "metadata": {},
   "source": [
    "### Tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e4824c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = tiktoken.encoding_for_model(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67febc00-7920-4b53-9c35-c21a0463422d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50257\n"
     ]
    }
   ],
   "source": [
    "print(enc.n_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a58440",
   "metadata": {},
   "source": [
    "## Prepare PyTorch Datasets and Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ac014e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = os.path.join(dataset_dir, train_file[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c29007b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_inst = NLPDataset(file_paths, enc)\n",
    "dataset = dataset_inst.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1e7d42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: torch.Size([635])\n",
      "Number of unique tokens: 268\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total tokens: {dataset.shape}\")\n",
    "print(f\"Number of unique tokens: {len(np.unique(dataset))}\")\n",
    "# print(f\"Number of chosen words to act as vocabulary (tokens): {len(int_mapping)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9def8720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 508\n",
      "Number of validation samples: 127\n"
     ]
    }
   ],
   "source": [
    "dataset_size = len(dataset)\n",
    "# Calculate the validation dataset size.\n",
    "valid_size = int(VALID_SPLIT*dataset_size)\n",
    "# Radomize the data indices.\n",
    "indices = torch.randperm(len(dataset)).tolist()\n",
    "# Training and validation sets.\n",
    "dataset_train = dataset[:-valid_size]\n",
    "dataset_valid = dataset[-valid_size:]\n",
    "\n",
    "# dataset_valid = NLPClassificationDataset()\n",
    "print(f\"Number of training samples: {len(dataset_train)}\")\n",
    "print(f\"Number of validation samples: {len(dataset_valid)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0361eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508\n",
      "127\n"
     ]
    }
   ],
   "source": [
    "print(dataset_train.size(0))\n",
    "print(dataset_valid.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afa95d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9e45605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   11 32138    11   290]\n",
      " [   11   810   262  7150]]\n",
      "[[32138    11   290 36578]\n",
      " [  810   262  7150  3947]]\n",
      "[', scrolls, and', ', where the trees']\n",
      "[' scrolls, and manuscripts', ' where the trees seemed']\n",
      "[[11135    13  1375  3767]\n",
      " [   11   290   262  2106]]\n",
      "[[  13 1375 3767  284]\n",
      " [ 290  262 2106  286]]\n",
      "[' roots. She continued', ', and the history']\n",
      "['. She continued to', ' and the history of']\n",
      "[[ 612 5615  257 1862]\n",
      " [2993  644  340 1244]]\n",
      "[[ 5615   257  1862  2576]\n",
      " [  644   340  1244 12116]]\n",
      "[' there lived a young', ' knew what it might']\n",
      "[' lived a young girl', ' what it might unlock']\n",
      "[[18966   373 13504   262]\n",
      " [36578    13 18966   338]]\n",
      "[[  373 13504   262  8222]\n",
      " [   13 18966   338  2951]]\n",
      "[' Emma was exploring the', \" manuscripts. Emma's\"]\n",
      "[' was exploring the forest', \". Emma's eyes\"]\n",
      "[[21405   326  3114   588]\n",
      " [ 8222    11   810   262]]\n",
      "[[ 326 3114  588  340]\n",
      " [  11  810  262 7150]]\n",
      "[' bark that looked like', ' forest, where the']\n",
      "[' that looked like it', ', where the trees']\n",
      "[[ 5380   607 11501    11]\n",
      " [13510  8215  1126  4335]]\n",
      "[[  607 11501    11   290]\n",
      " [ 8215  1126  4335  1280]]\n",
      "[' seek her wisdom,', ' wooden doors creaked']\n",
      "[' her wisdom, and', ' doors creaked open']\n",
      "[[  262  5888    11 18846]\n",
      " [ 3379 24613   329  8855]]\n",
      "[[ 5888    11 18846   262]\n",
      " [24613   329  8855    13]]\n",
      "[' the library, inserted', 'iable thirst for adventure']\n",
      "[' library, inserted the', ' thirst for adventure.']\n",
      "[[  262  8222    11   810]\n",
      " [11564 10377    11   290]]\n",
      "[[ 8222    11   810   262]\n",
      " [10377    11   290   262]]\n",
      "[' the forest, where', ' forgotten spells, and']\n",
      "[' forest, where the', ' spells, and the']\n",
      "[[   11   290   262  2106]\n",
      " [32897   351 14067    13]]\n",
      "[[  290   262  2106   286]\n",
      " [  351 14067    13  1375]]\n",
      "[', and the history', ' raced with excitement.']\n",
      "[' and the history of', ' with excitement. She']\n",
      "[[ 257 1994  588  340]\n",
      " [ 290  607 1035  265]]\n",
      "[[1994  588  340  878]\n",
      " [ 607 1035  265 3379]]\n",
      "[' a key like it', ' and her insat']\n",
      "[' key like it before', ' her insatiable']\n",
      "[[36578    13 18966   338]\n",
      " [ 7150  3947   284 31992]]\n",
      "[[   13 18966   338  2951]\n",
      " [ 3947   284 31992 13141]]\n",
      "[\" manuscripts. Emma's\", ' trees seemed to whisper']\n",
      "[\". Emma's eyes\", ' seemed to whisper secrets']\n",
      "[[  11  673 5071  257]\n",
      " [  13 1375 2993  428]]\n",
      "[[  673  5071   257 17304]\n",
      " [ 1375  2993   428  1994]]\n",
      "[', she discovered a', '. She knew this']\n",
      "[' she discovered a clearing', ' She knew this key']\n",
      "[[   11   355 18966   373]\n",
      " [ 5888   550   587 15283]]\n",
      "[[  355 18966   373 13504]\n",
      " [  550   587 15283   329]]\n",
      "[', as Emma was', ' library had been sealed']\n",
      "[' as Emma was exploring', ' had been sealed for']\n",
      "[[ 3641   286  4673   290]\n",
      " [ 7404 16343   992  1022]]\n",
      "[[  286  4673   290  3968]\n",
      " [16343   992  1022 10708]]\n",
      "[' center of learning and', ' village nestled between']\n",
      "[' of learning and culture', ' nestled between rolling']\n",
      "[[ 3690   262  7404   329]\n",
      " [  338  2612 32897   351]]\n",
      "[[  262  7404   329   607]\n",
      " [ 2612 32897   351 14067]]\n",
      "[' throughout the village for', \"'s heart raced with\"]\n",
      "[' the village for her', ' heart raced with excitement']\n",
      "[[  607 11501    11   290]\n",
      " [  290 36578    13 18966]]\n",
      "[[11501    11   290  9123]\n",
      " [36578    13 18966   338]]\n",
      "[' her wisdom, and', ' and manuscripts. Emma']\n",
      "[' wisdom, and scholars', \" manuscripts. Emma's\"]\n",
      "[[  198   198  1722 18966]\n",
      " [  992   351 14067   355]]\n",
      "[[  198  1722 18966 44716]\n",
      " [  351 14067   355   673]]\n",
      "['\\n\\nAs Emma', 'led with excitement as']\n",
      "['\\nAs Emma ventured', ' with excitement as she']\n",
      "[[  550  1775   257  1994]\n",
      " [  351 21405   326  3114]]\n",
      "[[ 1775   257  1994   588]\n",
      " [21405   326  3114   588]]\n",
      "[' had seen a key', ' with bark that looked']\n",
      "[' seen a key like', ' bark that looked like']\n",
      "[[7850  290 2951  355]\n",
      " [  11  290 2900  340]]\n",
      "[[ 290 2951  355 4171]\n",
      " [ 290 2900  340   13]]\n",
      "[' river and eyes as', ', and turned it']\n",
      "[' and eyes as blue', ' and turned it.']\n",
      "[[ 3108   673   550  1239]\n",
      " [18966   373 13504   262]]\n",
      "[[  673   550  1239  1775]\n",
      " [  373 13504   262  8222]]\n",
      "[' path she had never', ' Emma was exploring the']\n",
      "[' she had never seen', ' was exploring the forest']\n",
      "[[ 607 7404   13 1375]\n",
      " [ 284  262  890   12]]\n",
      "[[7404   13 1375 2627]\n",
      " [ 262  890   12 1640]]\n",
      "[' her village. She', ' to the long-']\n",
      "[' village. She became', ' the long-for']\n",
      "[[  198   198 26449   286]\n",
      " [10439   284  1282    13]]\n",
      "[[  198 26449   286 18966]\n",
      " [  284  1282    13   198]]\n",
      "['\\n\\nWord of', ' generations to come.']\n",
      "['\\nWord of Emma', ' to come.\\n']\n",
      "[[  257 17304  7365   704]\n",
      " [ 3725  7763  1626   373]]\n",
      "[[17304  7365   704   287]\n",
      " [ 7763  1626   373 17232]]\n",
      "[' a clearing bathed', ' knowledge contained within was']\n",
      "[' clearing bathed in', ' contained within was preserved']\n",
      "[[  607    13   198   198]\n",
      " [  355 18966   373 13504]]\n",
      "[[   13   198   198  1722]\n",
      " [18966   373 13504   262]]\n",
      "[' her.\\n\\n', ' as Emma was exploring']\n",
      "['.\\n\\nAs', ' Emma was exploring the']\n",
      "[[10708 18639    11   612]\n",
      " [12116    13   198   198]]\n",
      "[[18639    11   612  5615]\n",
      " [   13   198   198  2949]]\n",
      "[' rolling hills, there', ' unlock.\\n\\n']\n",
      "[' hills, there lived', '.\\n\\nNo']\n",
      "[[  284  1282    13   198]\n",
      " [ 1239 32012   607 11135]]\n",
      "[[ 1282    13   198   198]\n",
      " [32012   607 11135    13]]\n",
      "[' to come.\\n', ' never forgetting her roots']\n",
      "[' come.\\n\\n', ' forgetting her roots.']\n",
      "[[13524   364   422 12899]\n",
      " [  290 36578    13 18966]]\n",
      "[[  364   422 12899  8604]\n",
      " [36578    13 18966   338]]\n",
      "[' Travelers from distant', ' and manuscripts. Emma']\n",
      "['ers from distant lands', \" manuscripts. Emma's\"]\n",
      "[[  198  1537 31095   477]\n",
      " [   13   383  4334 13510]]\n",
      "[[ 1537 31095   477   262]\n",
      " [  383  4334 13510  8215]]\n",
      "['\\nBut amidst all', '. The heavy wooden']\n",
      "['But amidst all the', ' The heavy wooden doors']\n",
      "[[ 2402   257   640   287]\n",
      " [18359   645   640    13]]\n",
      "[[ 257  640  287  257]\n",
      " [ 645  640   13 1375]]\n",
      "[' upon a time in', ' wasted no time.']\n",
      "[' a time in a', ' no time. She']\n",
      "[[   13   198   198  1537]\n",
      " [  673   550 18838    13]]\n",
      "[[  198   198  1537 31095]\n",
      " [  550 18838    13 18966]]\n",
      "['.\\n\\nBut', ' she had uncovered.']\n",
      "['\\n\\nBut amidst', ' had uncovered. Emma']\n",
      "[[ 6156 13399   673   550]\n",
      " [ 3767   284  7301   262]]\n",
      "[[13399   673   550 18838]\n",
      " [  284  7301   262  8222]]\n",
      "[' ancient texts she had', ' continued to explore the']\n",
      "[' texts she had uncovered', ' to explore the forest']\n",
      "[[ 3706 18966    13 18966]\n",
      " [  198   198 10161  2611]]\n",
      "[[18966    13 18966   373]\n",
      " [  198 10161  2611 18359]]\n",
      "[' named Emma. Emma', '\\n\\nEmma']\n",
      "[' Emma. Emma was', '\\nEmma wasted']\n",
      "[[  554   262  3641   286]\n",
      " [13477 20726  2402 20726]]\n",
      "[[  262  3641   286   262]\n",
      " [20726  2402 20726   286]]\n",
      "[' In the center of', ' revealing shelves upon shelves']\n",
      "[' the center of the', ' shelves upon shelves of']\n",
      "[[  262 14068 42377   286]\n",
      " [  379   262  6156 13399]]\n",
      "[[14068 42377   286  3725]\n",
      " [  262  6156 13399   673]]\n",
      "[' the treasure trove of', ' at the ancient texts']\n",
      "[' treasure trove of knowledge', ' the ancient texts she']\n",
      "[[18966 44716  2252   656]\n",
      " [  287  1021    11   673]]\n",
      "[[44716  2252   656   262]\n",
      " [ 1021    11   673  4504]]\n",
      "[' Emma ventured further into', ' in hand, she']\n",
      "[' ventured further into the', ' hand, she returned']\n",
      "[[  550  1775 10675  1208]\n",
      " [  284   262  7404   290]]\n",
      "[[ 1775 10675  1208    13]\n",
      " [  262  7404   290  2540]]\n",
      "[' had seen centuries pass', ' to the village and']\n",
      "[' seen centuries pass.', ' the village and began']\n",
      "[[ 3931  1110    13   198]\n",
      " [13504   262  8222   326]]\n",
      "[[1110   13  198  198]\n",
      " [ 262 8222  326  275]]\n",
      "[' summer day.\\n', ' exploring the forest that']\n",
      "[' day.\\n\\n', ' the forest that b']\n",
      "[[ 1537 31095   477   262]\n",
      " [  550  1239  1775   878]]\n",
      "[[31095   477   262  3725]\n",
      " [ 1239  1775   878    13]]\n",
      "['But amidst all the', ' had never seen before']\n",
      "[' amidst all the knowledge', ' never seen before.']\n",
      "[[  383  3108  2957   607]\n",
      " [19695   290  1611    11]]\n",
      "[[3108 2957  607 2769]\n",
      " [ 290 1611   11 1239]]\n",
      "[' The path led her', ' humble and kind,']\n",
      "[' path led her deep', ' and kind, never']\n",
      "[[ 5986  4188  7404 16343]\n",
      " [  262  5793    11   290]]\n",
      "[[ 4188  7404 16343   992]\n",
      " [ 5793    11   290  2900]]\n",
      "[' picturesque village nest', ' the lock, and']\n",
      "['que village nestled', ' lock, and turned']\n",
      "[[  262  8222    11   810]\n",
      " [18966    13 18966   373]]\n",
      "[[ 8222    11   810   262]\n",
      " [   13 18966   373  1900]]\n",
      "[' the forest, where', ' Emma. Emma was']\n",
      "[' forest, where the', '. Emma was known']\n",
      "[[  290  3968    13   198]\n",
      " [20136   290   607  1035]]\n",
      "[[3968   13  198  198]\n",
      " [ 290  607 1035  265]]\n",
      "[' and culture.\\n', ' curiosity and her ins']\n",
      "[' culture.\\n\\n', ' and her insat']\n",
      "[[6766  319  257 1598]\n",
      " [  13 2080  262 1994]]\n",
      "[[ 319  257 1598 3931]\n",
      " [2080  262 1994  287]]\n",
      "[' sky on a clear', '. With the key']\n",
      "[' on a clear summer', ' With the key in']\n",
      "[[27737  3329    11   355]\n",
      " [  550   587 15283   329]]\n",
      "[[ 3329    11   355 18966]\n",
      " [  587 15283   329 10439]]\n",
      "[' sunny morning, as', ' had been sealed for']\n",
      "[' morning, as Emma', ' been sealed for generations']\n",
      "[[ 257 7104 3108  673]\n",
      " [ 673 3066  284 1061]]\n",
      "[[7104 3108  673  550]\n",
      " [3066  284 1061  340]]\n",
      "[' a hidden path she', ' she decided to follow']\n",
      "[' hidden path she had', ' decided to follow it']\n",
      "[[  326  3114   588   340]\n",
      " [18966  3377   607  1528]]\n",
      "[[ 3114   588   340   550]\n",
      " [ 3377   607  1528 37970]]\n",
      "[' that looked like it', ' Emma spent her days']\n",
      "[' looked like it had', ' spent her days immersed']\n",
      "[[10154   547   257 10715]\n",
      " [ 5615   257  1862  2576]]\n",
      "[[  547   257 10715   284]\n",
      " [  257  1862  2576  3706]]\n",
      "[' contents were a mystery', ' lived a young girl']\n",
      "[' were a mystery to', ' a young girl named']\n",
      "[[  257 10715   284   477]\n",
      " [ 3725   290  3241    11]]\n",
      "[[10715   284   477    13]\n",
      " [  290  3241    11 18966]]\n",
      "[' a mystery to all', ' knowledge and attention,']\n",
      "[' mystery to all.', ' and attention, Emma']\n",
      "[[  326   275 24071   262]\n",
      " [ 5986  4188  7404 16343]]\n",
      "[[  275 24071   262  7404]\n",
      " [ 4188  7404 16343   992]]\n",
      "[' that bordered the', ' picturesque village nest']\n",
      "[' bordered the village', 'que village nestled']\n",
      "[[37970   287   262  5888]\n",
      " [13504   262  8222   326]]\n",
      "[[ 287  262 5888   11]\n",
      " [ 262 8222  326  275]]\n",
      "[' immersed in the library', ' exploring the forest that']\n",
      "[' in the library,', ' the forest that b']\n",
      "[[ 1629   262  2779   286]\n",
      " [13999   284   262  5888]]\n",
      "[[ 262 2779  286  262]\n",
      " [ 284  262 5888   11]]\n",
      "[' At the base of', ' rushed to the library']\n",
      "[' the base of the', ' to the library,']\n",
      "[[  275 24071   262  7404]\n",
      " [24071   262  7404    11]]\n",
      "[[24071   262  7404    11]\n",
      " [  262  7404    11   673]]\n",
      "[' bordered the village', 'ordered the village,']\n",
      "['ordered the village,', ' the village, she']\n",
      "[[ 2993   428  1994  1276]\n",
      " [ 4190   326 35456   588]]\n",
      "[[  428  1994  1276 12116]\n",
      " [  326 35456   588   257]]\n",
      "[' knew this key must', ' hair that flowed like']\n",
      "[' this key must unlock', ' that flowed like a']\n",
      "[[10708 18639    11   612]\n",
      " [  329 10439    11   290]]\n",
      "[[18639    11   612  5615]\n",
      " [10439    11   290   663]]\n",
      "[' rolling hills, there', ' for generations, and']\n",
      "[' hills, there lived', ' generations, and its']\n",
      "[[  612  5615   257  1862]\n",
      " [21835  5220   326   340]]\n",
      "[[5615  257 1862 2576]\n",
      " [5220  326  340 1244]]\n",
      "[' there lived a young', ' Jenkins suggested that it']\n",
      "[' lived a young girl', ' suggested that it might']\n",
      "[[17304  7365   704   287]\n",
      " [ 3706  1770    13 21835]]\n",
      "[[ 7365   704   287 10861]\n",
      " [ 1770    13 21835  5220]]\n",
      "[' clearing bathed in', ' named Mr. Jenkins']\n",
      "[' bathed in golden', ' Mr. Jenkins suggested']\n",
      "[[1598 3931 1110   13]\n",
      " [7404  290 2540  284]]\n",
      "[[3931 1110   13  198]\n",
      " [ 290 2540  284 1265]]\n",
      "[' clear summer day.', ' village and began to']\n",
      "[' summer day.\\n', ' and began to ask']\n",
      "[[   13   198   198 10161]\n",
      " [  257 17304  7365   704]]\n",
      "[[  198   198 10161  2611]\n",
      " [17304  7365   704   287]]\n",
      "['.\\n\\nEm', ' a clearing bathed']\n",
      "['\\n\\nEmma', ' clearing bathed in']\n",
      "[[18966   338  7404 45671]\n",
      " [  351 14067   355   673]]\n",
      "[[  338  7404 45671   355]\n",
      " [14067   355   673 18782]]\n",
      "[\" Emma's village flourished\", ' with excitement as she']\n",
      "[\"'s village flourished as\", ' excitement as she explored']\n",
      "[[ 5421  1203 20136   290]\n",
      " [  284  1265   262 25263]]\n",
      "[[ 1203 20136   290   607]\n",
      " [ 1265   262 25263   611]]\n",
      "[' boundless curiosity and', ' to ask the villagers']\n",
      "['less curiosity and her', ' ask the villagers if']\n",
      "[[11501    11   290  9123]\n",
      " [  257  1402    11  5986]]\n",
      "[[   11   290  9123 22672]\n",
      " [ 1402    11  5986  4188]]\n",
      "[' wisdom, and scholars', ' a small, pictures']\n",
      "[', and scholars marvel', ' small, picturesque']\n",
      "[[3114  588  340  550]\n",
      " [ 262 2779  286  262]]\n",
      "[[ 588  340  550 1775]\n",
      " [2779  286  262 5509]]\n",
      "[' looked like it had', ' the base of the']\n",
      "[' like it had seen', ' base of the tree']\n",
      "[[12899  8604  1625   284]\n",
      " [ 2612 32897   351 14067]]\n",
      "[[ 8604  1625   284   262]\n",
      " [32897   351 14067    13]]\n",
      "[' distant lands came to', ' heart raced with excitement']\n",
      "[' lands came to the', ' raced with excitement.']\n",
      "[[ 6156 26210  5509   351]\n",
      " [ 2951  9009   992   351]]\n",
      "[[26210  5509   351 21405]\n",
      " [ 9009   992   351 14067]]\n",
      "[' ancient oak tree with', ' eyes sparkled with']\n",
      "[' oak tree with bark', ' sparkled with excitement']\n",
      "[[ 262 8222   11  673]\n",
      " [ 290 2951  355 4171]]\n",
      "[[8222   11  673 5071]\n",
      " [2951  355 4171  355]]\n",
      "[' the forest, she', ' and eyes as blue']\n",
      "[' forest, she discovered', ' eyes as blue as']\n",
      "[[ 262 8222   11  673]\n",
      " [ 878   13 2558 4359]]\n",
      "[[8222   11  673 5071]\n",
      " [  13 2558 4359 1739]]\n",
      "[' the forest, she', ' before. Intrig']\n",
      "[' forest, she discovered', '. Intrigued']\n",
      "[[2993  428 1994 1276]\n",
      " [2949  530  287  262]]\n",
      "[[  428  1994  1276 12116]\n",
      " [  530   287   262  7404]]\n",
      "[' knew this key must', 'No one in the']\n",
      "[' this key must unlock', ' one in the village']\n",
      "[[ 1402    11 25322   378]\n",
      " [11135    13  1375  3767]]\n",
      "[[   11 25322   378  1994]\n",
      " [   13  1375  3767   284]]\n",
      "[' small, ornate', ' roots. She continued']\n",
      "[', ornate key', '. She continued to']\n",
      "[[ 1862  2576  3706 18966]\n",
      " [11564 10377    11   290]]\n",
      "[[ 2576  3706 18966    13]\n",
      " [10377    11   290   262]]\n",
      "[' young girl named Emma', ' forgotten spells, and']\n",
      "[' girl named Emma.', ' spells, and the']\n",
      "[[   11  7721 14930  4190]\n",
      " [   11   355 18966   373]]\n",
      "[[ 7721 14930  4190   326]\n",
      " [  355 18966   373 13504]]\n",
      "[', chestnut hair', ', as Emma was']\n",
      "[' chestnut hair that', ' as Emma was exploring']\n",
      "[[  257 17304  7365   704]\n",
      " [  550 18838    13 18966]]\n",
      "[[17304  7365   704   287]\n",
      " [18838    13 18966   338]]\n",
      "[' a clearing bathed', ' had uncovered. Emma']\n",
      "[' clearing bathed in', \" uncovered. Emma's\"]\n",
      "[[  319   257  1598  3931]\n",
      " [18966   338  2951  9009]]\n",
      "[[ 257 1598 3931 1110]\n",
      " [ 338 2951 9009  992]]\n",
      "[' on a clear summer', \" Emma's eyes spark\"]\n",
      "[' a clear summer day', \"'s eyes sparkled\"]\n",
      "[[ 287 1021   11  673]\n",
      " [ 810  262 7150 3947]]\n",
      "[[1021   11  673 4504]\n",
      " [ 262 7150 3947  284]]\n",
      "[' in hand, she', ' where the trees seemed']\n",
      "[' hand, she returned', ' the trees seemed to']\n",
      "[[  290   663 10154   547]\n",
      " [45671   355   340  2627]]\n",
      "[[  663 10154   547   257]\n",
      " [  355   340  2627   257]]\n",
      "[' and its contents were', ' flourished as it became']\n",
      "[' its contents were a', ' as it became a']\n",
      "[[18966    13 18966   373]\n",
      " [  656   262  8222    11]]\n",
      "[[   13 18966   373  1900]\n",
      " [  262  8222    11   673]]\n",
      "[' Emma. Emma was', ' into the forest,']\n",
      "['. Emma was known', ' the forest, she']\n",
      "[[18966   373  1900  3690]\n",
      " [ 5071   257 17304  7365]]\n",
      "[[  373  1900  3690   262]\n",
      " [  257 17304  7365   704]]\n",
      "[' Emma was known throughout', ' discovered a clearing bat']\n",
      "[' was known throughout the', ' a clearing bathed']\n",
      "[[   11   673  5071   257]\n",
      " [  265  3379 24613   329]]\n",
      "[[  673  5071   257 17304]\n",
      " [ 3379 24613   329  8855]]\n",
      "[', she discovered a', 'atiable thirst for']\n",
      "[' she discovered a clearing', 'iable thirst for adventure']\n",
      "[[  198  3198 27737  3329]\n",
      " [ 3706 18966    13 18966]]\n",
      "[[ 3198 27737  3329    11]\n",
      " [18966    13 18966   373]]\n",
      "['\\nOne sunny morning', ' named Emma. Emma']\n",
      "['One sunny morning,', ' Emma. Emma was']\n",
      "[[ 2576  3706 18966    13]\n",
      " [32897   351 14067    13]]\n",
      "[[ 3706 18966    13 18966]\n",
      " [  351 14067    13  1375]]\n",
      "[' girl named Emma.', ' raced with excitement.']\n",
      "[' named Emma. Emma', ' with excitement. She']\n",
      "[[  262  7404   284  5380]\n",
      " [ 7365   704   287 10861]]\n",
      "[[ 7404   284  5380   607]\n",
      " [  704   287 10861 19606]]\n",
      "[' the village to seek', ' bathed in golden']\n",
      "[' village to seek her', 'hed in golden sunlight']\n",
      "[[   13  1629   262  2779]\n",
      " [ 2612 32897   351 14067]]\n",
      "[[ 1629   262  2779   286]\n",
      " [32897   351 14067    13]]\n",
      "['. At the base', ' heart raced with excitement']\n",
      "[' At the base of', ' raced with excitement.']\n",
      "[[ 2611   338  2612 32897]\n",
      " [  284 31992 13141   284]]\n",
      "[[  338  2612 32897   351]\n",
      " [31992 13141   284   262]]\n",
      "[\"ma's heart raced\", ' to whisper secrets to']\n",
      "[\"'s heart raced with\", ' whisper secrets to the']\n",
      "[[ 338 2951 9009  992]\n",
      " [ 640   13 2080  262]]\n",
      "[[2951 9009  992  351]\n",
      " [  13 2080  262 1994]]\n",
      "[\"'s eyes sparkled\", ' time. With the']\n",
      "[' eyes sparkled with', '. With the key']\n",
      "[[  262  6156 13399   673]\n",
      " [35456   588   257  7850]]\n",
      "[[ 6156 13399   673   550]\n",
      " [  588   257  7850   290]]\n",
      "[' the ancient texts she', ' flowed like a river']\n",
      "[' ancient texts she had', ' like a river and']\n",
      "[[18782   262 14068 42377]\n",
      " [  286 13273  8109    11]]\n",
      "[[  262 14068 42377   286]\n",
      " [13273  8109    11 11564]]\n",
      "[' explored the treasure trove', ' of legendary creatures,']\n",
      "[' the treasure trove of', ' legendary creatures, forgotten']\n",
      "[[ 3377   607  1528 37970]\n",
      " [   13 21835  5220   326]]\n",
      "[[  607  1528 37970   287]\n",
      " [21835  5220   326   340]]\n",
      "[' spent her days immersed', '. Jenkins suggested that']\n",
      "[' her days immersed in', ' Jenkins suggested that it']\n",
      "[[  477    13   198   198]\n",
      " [   13 18966   373  1900]]\n",
      "[[   13   198   198 10161]\n",
      " [18966   373  1900  3690]]\n",
      "[' all.\\n\\n', '. Emma was known']\n",
      "['.\\n\\nEm', ' Emma was known throughout']\n",
      "[[ 607 1035  265 3379]\n",
      " [5793   11  290 2900]]\n",
      "[[ 1035   265  3379 24613]\n",
      " [   11   290  2900   340]]\n",
      "[' her insatiable', ' lock, and turned']\n",
      "[' insatiable thirst', ', and turned it']\n",
      "[[ 1770    13 21835  5220]\n",
      " [ 2252   656   262  8222]]\n",
      "[[   13 21835  5220   326]\n",
      " [  656   262  8222    11]]\n",
      "[' Mr. Jenkins suggested', ' further into the forest']\n",
      "['. Jenkins suggested that', ' into the forest,']\n",
      "[[35808  3706  1770    13]\n",
      " [  290  9123 22672   276]]\n",
      "[[ 3706  1770    13 21835]\n",
      " [ 9123 22672   276   379]]\n",
      "['ibrarian named Mr.', ' and scholars marveled']\n",
      "[' named Mr. Jenkins', ' scholars marveled at']\n",
      "[[  198   198 26449   286]\n",
      " [  290   607  1035   265]]\n",
      "[[  198 26449   286 18966]\n",
      " [  607  1035   265  3379]]\n",
      "['\\n\\nWord of', ' and her insat']\n",
      "['\\nWord of Emma', ' her insatiable']\n",
      "[[  326  3114   588   340]\n",
      " [ 7404 16343   992  1022]]\n",
      "[[ 3114   588   340   550]\n",
      " [16343   992  1022 10708]]\n",
      "[' that looked like it', ' village nestled between']\n",
      "[' looked like it had', ' nestled between rolling']\n",
      "[[  13 2558 4359 1739]\n",
      " [  11  612 5615  257]]\n",
      "[[2558 4359 1739   11]\n",
      " [ 612 5615  257 1862]]\n",
      "['. Intrigued', ', there lived a']\n",
      "[' Intrigued,', ' there lived a young']\n",
      "[[10861 19606    13   554]\n",
      " [ 3767   284  7301   262]]\n",
      "[[19606    13   554   262]\n",
      " [  284  7301   262  8222]]\n",
      "[' golden sunlight. In', ' continued to explore the']\n",
      "[' sunlight. In the', ' to explore the forest']\n",
      "[[ 5220   326   340  1244]\n",
      " [ 3706 18966    13 18966]]\n",
      "[[  326   340  1244   307]\n",
      " [18966    13 18966   373]]\n",
      "[' suggested that it might', ' named Emma. Emma']\n",
      "[' that it might be', ' Emma. Emma was']\n",
      "[[ 2993   644   340  1244]\n",
      " [ 1611    11  1239 32012]]\n",
      "[[  644   340  1244 12116]\n",
      " [   11  1239 32012   607]]\n",
      "[' knew what it might', ' kind, never forgetting']\n",
      "[' what it might unlock', ', never forgetting her']\n",
      "[[  262  2779   286   262]\n",
      " [  663 10154   547   257]]\n",
      "[[ 2779   286   262  5509]\n",
      " [10154   547   257 10715]]\n",
      "[' the base of the', ' its contents were a']\n",
      "[' base of the tree', ' contents were a mystery']\n",
      "[[1497  329  257  890]\n",
      " [ 326  262 3725 7763]]\n",
      "[[ 329  257  890  640]\n",
      " [ 262 3725 7763 1626]]\n",
      "[' away for a long', ' that the knowledge contained']\n",
      "[' for a long time', ' the knowledge contained within']\n",
      "[[   11 25322   378  1994]\n",
      " [11564 10377    11   290]]\n",
      "[[25322   378  1994    13]\n",
      " [10377    11   290   262]]\n",
      "[', ornate key', ' forgotten spells, and']\n",
      "[' ornate key.', ' spells, and the']\n",
      "[[  290  3968    13   198]\n",
      " [ 7365   704   287 10861]]\n",
      "[[ 3968    13   198   198]\n",
      " [  704   287 10861 19606]]\n",
      "[' and culture.\\n', ' bathed in golden']\n",
      "[' culture.\\n\\n', 'hed in golden sunlight']\n"
     ]
    }
   ],
   "source": [
    "# for i, batch in enumerate(dataset_train):\n",
    "#     inp, tgt = get_batch('train')\n",
    "#     print(inp)\n",
    "#     print(tgt)\n",
    "#     inp_words = ''\n",
    "#     tgt_words = ''\n",
    "#     inp = inp[0].cpu().numpy()\n",
    "#     tgt = tgt[0].cpu().numpy()\n",
    "#     print(len(inp))\n",
    "#     print(len(tgt))\n",
    "#     for idx in inp:\n",
    "#         inp_words += ' ' + int2word_train[idx]\n",
    "#     print(inp_words)\n",
    "#     print('*'*50)\n",
    "#     for idx in tgt:\n",
    "#         tgt_words += ' ' + int2word_train[idx]\n",
    "#     print(tgt_words)\n",
    "#     if i == 2:\n",
    "#         break\n",
    "\n",
    "for i in range(100):\n",
    "    inp, tgt = get_batch(dataset_train, sequence_length=4, batch_size=2)\n",
    "    print(inp.numpy())\n",
    "    print(tgt.numpy())\n",
    "    print(enc.decode_batch(inp.numpy()))\n",
    "    print(enc.decode_batch(tgt.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66743536",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8366cbd0-48d1-4776-9300-7ccfc66b7006",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz):\n",
    "    \"\"\"\n",
    "    Generate a square mask for the sequence. The masked positions are filled with float('-inf').\n",
    "    Unmasked positions are filled with float(0.0).\n",
    "    \"\"\"\n",
    "    mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55e810ee-d9cc-436e-8131-038f549f732f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, max_len, d_model, dropout=0.1):\n",
    "        \"\"\"\n",
    "        :param max_len: Input length sequence.\n",
    "        :param d_model: Embedding dimension.\n",
    "        :param dropout: Dropout value (default=0.1)\n",
    "        \"\"\"\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Inputs of forward function\n",
    "        :param x: the sequence fed to the positional encoder model (required).\n",
    "        Shape:\n",
    "            x: [sequence length, batch size, embed dim]\n",
    "            output: [sequence length, batch size, embed dim]\n",
    "        \"\"\"\n",
    "\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "513af03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGen(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_layers, num_heads):\n",
    "        super(TextGen, self).__init__()\n",
    "        self.pos_encoder = PositionalEncoding(max_len=SEQUENCE_LENGTH, d_model=embed_dim)\n",
    "        self.emb = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.decoder_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=embed_dim, \n",
    "            nhead=num_heads, \n",
    "            batch_first=True\n",
    "        )\n",
    "        self.decoder = nn.TransformerDecoder(\n",
    "            decoder_layer=self.decoder_layer,\n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "        self.linear = nn.Linear(embed_dim, vocab_size)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    # Positional encoding is required. Else the model does not learn.\n",
    "    def forward(self, x):\n",
    "        emb = self.emb(x)\n",
    "        \n",
    "        # Generate input sequence mask with shape (SEQUENCE_LENGTH, SEQUENCE_LENGTH)\n",
    "        input_mask = generate_square_subsequent_mask(x.size(1)).to(x.device)\n",
    "        \n",
    "        x = self.pos_encoder(emb)\n",
    "        x = self.decoder(x, memory=x, tgt_mask=input_mask, memory_mask=input_mask)\n",
    "        x = self.dropout(x)\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a6f1862-5725-4ac4-b801-7775f9b16911",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextGen(\n",
    "    vocab_size=NUM_WORDS, \n",
    "    embed_dim=100,\n",
    "    num_layers=2, \n",
    "    num_heads=2,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5621ac84",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5508f234",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b96fd55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextGen(\n",
      "  (pos_encoder): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (emb): Embedding(50257, 100)\n",
      "  (decoder_layer): TransformerDecoderLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=100, out_features=100, bias=True)\n",
      "    )\n",
      "    (multihead_attn): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=100, out_features=100, bias=True)\n",
      "    )\n",
      "    (linear1): Linear(in_features=100, out_features=2048, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (linear2): Linear(in_features=2048, out_features=100, bias=True)\n",
      "    (norm1): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm3): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout1): Dropout(p=0.1, inplace=False)\n",
      "    (dropout2): Dropout(p=0.1, inplace=False)\n",
      "    (dropout3): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-1): 2 x TransformerDecoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=100, out_features=100, bias=True)\n",
      "        )\n",
      "        (multihead_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=100, out_features=100, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=100, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=100, bias=True)\n",
      "        (norm1): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (dropout3): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (linear): Linear(in_features=100, out_features=50257, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "11,581,101 total parameters.\n",
      "11,581,101 training parameters.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(), \n",
    "    lr=0.0001,\n",
    ")\n",
    "\n",
    "# StepLR every specific number of epochs.\n",
    "scheduler = StepLR(\n",
    "    optimizer, \n",
    "    step_size=5, \n",
    "    gamma=0.5,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Total parameters and trainable parameters.\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"{total_params:,} total parameters.\")\n",
    "total_trainable_params = sum(\n",
    "    p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"{total_trainable_params:,} training parameters.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "999052b3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Iteration 1 of 10000\n",
      "Training loss: 10.967938423156738\n",
      "Validation loss: 10.847050666809082\n",
      "--------------------------------------------------\n",
      "[INFO]: Iteration 251 of 10000\n",
      "Training loss: 4.941972255706787\n",
      "Validation loss: 7.1813554763793945\n",
      "--------------------------------------------------\n",
      "[INFO]: Iteration 501 of 10000\n",
      "Training loss: 2.375515937805176\n",
      "Validation loss: 6.413870811462402\n",
      "--------------------------------------------------\n",
      "[INFO]: Iteration 751 of 10000\n",
      "Training loss: 1.0199147462844849\n",
      "Validation loss: 6.7280378341674805\n",
      "--------------------------------------------------\n",
      "[INFO]: Iteration 1001 of 10000\n",
      "Training loss: 0.6438777446746826\n",
      "Validation loss: 7.132083892822266\n",
      "--------------------------------------------------\n",
      "[INFO]: Iteration 1251 of 10000\n",
      "Training loss: 0.3067123293876648\n",
      "Validation loss: 7.441065788269043\n",
      "--------------------------------------------------\n",
      "[INFO]: Iteration 1501 of 10000\n",
      "Training loss: 0.18762174248695374\n",
      "Validation loss: 7.640043258666992\n",
      "--------------------------------------------------\n",
      "[INFO]: Iteration 1751 of 10000\n",
      "Training loss: 0.13864576816558838\n",
      "Validation loss: 7.837040424346924\n",
      "--------------------------------------------------\n",
      "[INFO]: Iteration 2001 of 10000\n",
      "Training loss: 0.11201690882444382\n",
      "Validation loss: 8.033844947814941\n",
      "--------------------------------------------------\n",
      "[INFO]: Iteration 2251 of 10000\n",
      "Training loss: 0.11829175800085068\n",
      "Validation loss: 8.189852714538574\n",
      "--------------------------------------------------\n",
      "[INFO]: Iteration 2501 of 10000\n",
      "Training loss: 0.0863443911075592\n",
      "Validation loss: 8.31936264038086\n",
      "--------------------------------------------------\n",
      "[INFO]: Iteration 2751 of 10000\n",
      "Training loss: 0.060556717216968536\n",
      "Validation loss: 8.493067741394043\n",
      "--------------------------------------------------\n",
      "[INFO]: Iteration 3001 of 10000\n",
      "Training loss: 0.05130412057042122\n",
      "Validation loss: 8.513928413391113\n",
      "--------------------------------------------------\n",
      "[INFO]: Iteration 3251 of 10000\n",
      "Training loss: 0.05209388583898544\n",
      "Validation loss: 8.68696403503418\n",
      "--------------------------------------------------\n",
      "[INFO]: Iteration 3501 of 10000\n",
      "Training loss: 0.052519407123327255\n",
      "Validation loss: 8.801774978637695\n",
      "--------------------------------------------------\n",
      "[INFO]: Iteration 3751 of 10000\n",
      "Training loss: 0.046567246317863464\n",
      "Validation loss: 8.809503555297852\n",
      "--------------------------------------------------\n",
      "[INFO]: Iteration 4001 of 10000\n",
      "Training loss: 0.03853346407413483\n",
      "Validation loss: 8.940945625305176\n",
      "--------------------------------------------------\n",
      "[INFO]: Iteration 4251 of 10000\n",
      "Training loss: 0.037666644901037216\n",
      "Validation loss: 9.010749816894531\n",
      "--------------------------------------------------\n",
      "[INFO]: Iteration 4501 of 10000\n",
      "Training loss: 0.03393402695655823\n",
      "Validation loss: 9.153871536254883\n",
      "--------------------------------------------------\n",
      "[INFO]: Iteration 4751 of 10000\n",
      "Training loss: 0.03373963385820389\n",
      "Validation loss: 9.161205291748047\n",
      "--------------------------------------------------\n",
      "[INFO]: Iteration 5001 of 10000\n",
      "Training loss: 0.025081692263484\n",
      "Validation loss: 9.265413284301758\n",
      "--------------------------------------------------\n",
      "[INFO]: Iteration 5251 of 10000\n",
      "Training loss: 0.035753510892391205\n",
      "Validation loss: 9.317683219909668\n",
      "--------------------------------------------------\n",
      "[INFO]: Iteration 5501 of 10000\n",
      "Training loss: 0.031601715832948685\n",
      "Validation loss: 9.371404647827148\n",
      "--------------------------------------------------\n",
      "[INFO]: Iteration 5751 of 10000\n",
      "Training loss: 0.02198141999542713\n",
      "Validation loss: 9.488359451293945\n",
      "--------------------------------------------------\n",
      "[INFO]: Iteration 6001 of 10000\n",
      "Training loss: 0.02732611447572708\n",
      "Validation loss: 9.542340278625488\n",
      "--------------------------------------------------\n",
      "[INFO]: Iteration 6251 of 10000\n",
      "Training loss: 0.034989435225725174\n",
      "Validation loss: 9.517648696899414\n",
      "--------------------------------------------------\n",
      "[INFO]: Iteration 6501 of 10000\n",
      "Training loss: 0.019040267914533615\n",
      "Validation loss: 9.687640190124512\n",
      "--------------------------------------------------\n",
      "[INFO]: Iteration 6751 of 10000\n",
      "Training loss: 0.019473306834697723\n",
      "Validation loss: 9.797430038452148\n",
      "--------------------------------------------------\n",
      "[INFO]: Iteration 7001 of 10000\n",
      "Training loss: 0.025278635323047638\n",
      "Validation loss: 9.82075023651123\n",
      "--------------------------------------------------\n",
      "[INFO]: Iteration 7251 of 10000\n",
      "Training loss: 0.02840210124850273\n",
      "Validation loss: 9.889608383178711\n",
      "--------------------------------------------------\n",
      "[INFO]: Iteration 7501 of 10000\n",
      "Training loss: 0.0296268779784441\n",
      "Validation loss: 9.89416790008545\n",
      "--------------------------------------------------\n",
      "[INFO]: Iteration 7751 of 10000\n",
      "Training loss: 0.025397395715117455\n",
      "Validation loss: 9.950679779052734\n",
      "--------------------------------------------------\n",
      "[INFO]: Iteration 8001 of 10000\n",
      "Training loss: 0.02286042459309101\n",
      "Validation loss: 10.172036170959473\n",
      "--------------------------------------------------\n",
      "[INFO]: Iteration 8251 of 10000\n",
      "Training loss: 0.030529910698533058\n",
      "Validation loss: 10.115939140319824\n",
      "--------------------------------------------------\n",
      "[INFO]: Iteration 8501 of 10000\n",
      "Training loss: 0.02766912244260311\n",
      "Validation loss: 10.221349716186523\n",
      "--------------------------------------------------\n",
      "[INFO]: Iteration 8751 of 10000\n",
      "Training loss: 0.017833389341831207\n",
      "Validation loss: 10.172751426696777\n",
      "--------------------------------------------------\n",
      "[INFO]: Iteration 9001 of 10000\n",
      "Training loss: 0.02346443012356758\n",
      "Validation loss: 10.204750061035156\n",
      "--------------------------------------------------\n",
      "[INFO]: Iteration 9251 of 10000\n",
      "Training loss: 0.020948102697730064\n",
      "Validation loss: 10.273924827575684\n",
      "--------------------------------------------------\n",
      "[INFO]: Iteration 9501 of 10000\n",
      "Training loss: 0.016172371804714203\n",
      "Validation loss: 10.346793174743652\n",
      "--------------------------------------------------\n",
      "[INFO]: Iteration 9751 of 10000\n",
      "Training loss: 0.025083906948566437\n",
      "Validation loss: 10.467489242553711\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Lists to keep track of losses and accuracies.\n",
    "train_loss, valid_loss = [], []\n",
    "# Start the training.\n",
    "for iteration in range(MAX_ITERS):\n",
    "    train_step_loss = train_step(\n",
    "        model, \n",
    "        dataset_train, \n",
    "        optimizer, \n",
    "        criterion,\n",
    "        SEQUENCE_LENGTH,\n",
    "        NUM_WORDS,\n",
    "        BATCH_SIZE,\n",
    "        device\n",
    "    )\n",
    "    valid_step_loss = val_step(\n",
    "        model, \n",
    "        dataset_valid,  \n",
    "        criterion,\n",
    "        SEQUENCE_LENGTH,\n",
    "        NUM_WORDS,\n",
    "        BATCH_SIZE,\n",
    "        device\n",
    "    )\n",
    "    train_loss.append(train_step_loss.cpu().detach().numpy())\n",
    "    valid_loss.append(valid_step_loss.cpu().detach().numpy())\n",
    "    if iteration % 250 == 0:\n",
    "        print(f\"[INFO]: Iteration {iteration+1} of {MAX_ITERS}\")\n",
    "        print(f\"Training loss: {train_step_loss}\")\n",
    "        print(f\"Validation loss: {valid_step_loss}\")\n",
    "        print('-'*50)\n",
    "    #     if epoch + 1 <= 32:\n",
    "#         scheduler.step()\n",
    "# Save model.\n",
    "torch.save(\n",
    "    model, os.path.join(CHECKPOINT_DIR, 'model.pth')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d589742-d6e2-4af3-881f-3584fd588ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model.\n",
    "torch.save(\n",
    "    model, os.path.join(CHECKPOINT_DIR, 'model.pth')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "56e504f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plots(train_loss, valid_loss):\n",
    "    \"\"\"\n",
    "    Function to save the loss and accuracy plots to disk.\n",
    "    \"\"\"\n",
    "    plt.show()\n",
    "    # Loss plots.\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot(\n",
    "        train_loss, color='blue', linestyle='-', \n",
    "        label='train loss'\n",
    "    )\n",
    "    plt.plot(\n",
    "        valid_loss, color='red', linestyle='-', \n",
    "        label='validataion loss'\n",
    "    )\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "#     plt.savefig(f\"../outputs/loss.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5e4eced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_plots(train_loss, valid_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee6468b",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c3810a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = torch.load(\n",
    "    os.path.join(CHECKPOINT_DIR, 'model.pth')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "01bc10b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loss = validate(\n",
    "#     trained_model, \n",
    "#     dataset_test,  \n",
    "#     criterion, \n",
    "#     device\n",
    "# )\n",
    "\n",
    "# print(f\"Test loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86e1a2f",
   "metadata": {},
   "source": [
    "## Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f269eb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_int_vector(enc, text):\n",
    "        \"\"\"\n",
    "        Assign an integer to each word and return the integers in a list.\n",
    "        \"\"\"\n",
    "        return enc.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f9e7817",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = tiktoken.encoding_for_model(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c11d2a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sample_next(predictions, temperature=1.0):\n",
    "#     \"\"\"\n",
    "#     Implement variable-temperature sampling from a probability\n",
    "#     distribution.\n",
    "#     \"\"\"\n",
    "#     predictions = predictions.squeeze(0)[-1, :] / temperature\n",
    "#     predictions = predictions.exp().cpu()\n",
    "#     next_token = torch.multinomial(predictions, num_samples=1)\n",
    "#     return int(next_token[0].cpu())\n",
    "\n",
    "# def text_generator(sentence, generate_length):\n",
    "#     trained_model.eval()\n",
    "#     temperatures = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0] \n",
    "#     for temperature in temperatures:\n",
    "#         sample = sentence\n",
    "#         print(f\"GENERATED SENTENCE WITH TEMPERATURE {temperature}\")\n",
    "#         for i in range(generate_length):\n",
    "#             int_vector = return_int_vector(enc, sample)\n",
    "#             if len(int_vector) >= SEQUENCE_LENGTH - 1:\n",
    "#                 break\n",
    "#             input_tensor = torch.tensor(int_vector, dtype=torch.int32)\n",
    "#             input_tensor = input_tensor.unsqueeze(0).to(device)\n",
    "#             with torch.no_grad():\n",
    "#                 predictions = trained_model(input_tensor)\n",
    "#             next_token = sample_next(predictions, temperature)\n",
    "# #             if next_token != 0: # Ignore <pad> index. Final sentence may be shorter.\n",
    "#             sample += enc.decode([next_token])\n",
    "#         print(sample)\n",
    "#         print('\\n')\n",
    "\n",
    "def sample_next(predictions, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Implement variable-temperature sampling from a probability\n",
    "    distribution.\n",
    "    \"\"\"\n",
    "    # print(predictions.shape)\n",
    "    predictions = predictions[:, -1, :] / temperature\n",
    "    # print(predictions.shape)\n",
    "    # print(torch.where(predictions > 0))\n",
    "    probabilities = F.softmax(predictions, dim=-1).cpu()\n",
    "    # print(probabilities.shape)\n",
    "    next_token = torch.multinomial(probabilities, num_samples=1)\n",
    "    # print(next_token)\n",
    "    return int(next_token.cpu())\n",
    "\n",
    "def text_generator(sentence, generate_length):\n",
    "    trained_model.eval()\n",
    "    temperatures = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2.0] \n",
    "    for temperature in temperatures:\n",
    "        sample = sentence\n",
    "        print(f\"GENERATED SENTENCE WITH TEMPERATURE {temperature}\")\n",
    "        for i in range(generate_length):\n",
    "            # print(f\"Sample: {sample}\")\n",
    "            int_vector = return_int_vector(enc, sample)\n",
    "            if len(int_vector) >= SEQUENCE_LENGTH - 1:\n",
    "                break\n",
    "            input_tensor = torch.tensor(int_vector, dtype=torch.long).to(device)  # Changed dtype to torch.long\n",
    "            input_tensor = input_tensor.unsqueeze(0)\n",
    "            with torch.no_grad():\n",
    "                predictions = trained_model(input_tensor)\n",
    "            next_token = sample_next(predictions, temperature)  # Pass the temperature to the sample function\n",
    "            sample += enc.decode([next_token])\n",
    "        print(sample)\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9d418dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"Once upon a time in a small, picturesque village nestled\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2afbe177",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9822d8b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT: Once upon a time in a small, picturesque village nestled\n",
      "GENERATED SENTENCE WITH TEMPERATURE 0.1\n",
      "Once upon a time in a small, picturesque village nestled between rolling hills, there lived a young girl named Emma. Emma was known throughout the village for her boundless curiosity and her insatiable thirst for adventure. She had long, chestnut hair that flowed like a river and eyes as blue as the sky on a clear summer day.\n",
      "\n",
      " that bordered the village, she stumbled upon a hidden path she had never seen before. Intrigued, she decided to follow it.\n",
      "\n",
      "\n",
      "GENERATED SENTENCE WITH TEMPERATURE 0.2\n",
      "Once upon a time in a small, picturesque village nestled between rolling hills, there lived a young girl named Emma. Emma was known throughout the village for her boundless curiosity and her insatiable thirst for adventure. She had long, chestnut hair that flowed like a river and eyes as blue as the sky on a clear summer day.\n",
      "\n",
      " that bordered the village, she stumbled upon a hidden path she had never seen before. Intrigued, she decided to follow it.\n",
      "\n",
      "\n",
      "GENERATED SENTENCE WITH TEMPERATURE 0.3\n",
      "Once upon a time in a small, picturesque village nestled between rolling hills, there lived a young girl named Emma. Emma was known throughout the village for her boundless curiosity and her insatiable thirst for adventure. She had long, chestnut hair that flowed like a river and eyes as blue as the sky on a clear summer day.\n",
      "\n",
      " that bordered the village, as the village, she stumbled upon a hidden path she had never seen before. Intrigued, she decided\n",
      "\n",
      "\n",
      "GENERATED SENTENCE WITH TEMPERATURE 0.4\n",
      "Once upon a time in a small, picturesque village nestled between rolling hills, there lived a young girl named Emma. Emma was known throughout the village for her boundless curiosity and her insatiable thirst for adventure. She had long, chestnut hair that flowed like a river and eyes as blue as the sky on a clear summer day.\n",
      "\n",
      " that bordered the village, as the village, she stumbled upon a hidden path she had never seen before. Intrigued, sheJOHN\n",
      "\n",
      "\n",
      "GENERATED SENTENCE WITH TEMPERATURE 0.5\n",
      "Once upon a time in a small, picturesque village nestled between rolling hills, there lived a young girl named Emma. Emma was known throughout the village for her boundless curiosity and her insatiable thirst for adventure. She had long, chestnut hair that flowed like a river and eyes as blue as the sky on a clear summer day.\n",
      "\n",
      " that bordered the village, as the village, she stumbled upon a hidden path she had never seenioxid the forest, she had never seen\n",
      "\n",
      "\n",
      "GENERATED SENTENCE WITH TEMPERATURE 0.6\n",
      "Once upon a time in a small, picturesque village nestled between rolling hills, there lived a young girl named Emma. Emma was known throughout the village for her boundless curiosity and her insatiable thirst for adventure. She had long, chestnut hair that flowed like a river and eyes as blue as the sky on a clear summer day.\n",
      "\n",
      " that bordered the village, she stumbled upon a hidden path she had never seen before. Intrigued, she decided to follow it.\n",
      "\n",
      "\n",
      "GENERATED SENTENCE WITH TEMPERATURE 0.7\n",
      "Once upon a time in a small, picturesque village nestled between rolling hills, there lived a young girl named Emma. Emma was known throughout the village for her boundless curiosity and her insatiable thirst for adventure. She had long, chestnut hair that flowed like a river and eyes as blue as the sky on a clear summer day.\n",
      "\n",
      " that bordered the village, she stumbled upon a hidden path she had never seen before. Intrigued, she decided to follow it.\n",
      "\n",
      "\n",
      "GENERATED SENTENCE WITH TEMPERATURE 0.8\n",
      "Once upon a time in a small, picturesque village nestled between rolling hills, there lived a young girl named Emma. Emma was known throughout the village for her boundless curiosity and her insatiable thirst for adventure. She had long, chestnut hair that flowed like a river and eyes as blue as the sky on a clear summer day.\n",
      "\n",
      " that flowed like a clear summer day.\n",
      "\n",
      " the sky on a clear summer day.\n",
      "\n",
      " the library, she discovered tales of legendary creatures,\n",
      "\n",
      "\n",
      "GENERATED SENTENCE WITH TEMPERATURE 0.9\n",
      "Once upon a time in a small, picturesque village nestled between rolling hills, there lived a young girl named Emma. Emma was known throughout the village for her boundless curiosity and her insatiable thirst for adventure. She had long, chestnut hair that flowed like a river and eyes as blue as the sky on a clear summer day.\n",
      "\n",
      " clear summer day.\n",
      "\n",
      "que village, as Emma was exploring the forest that bordered the village, she stumbled upon a hidden path she\n",
      "\n",
      "\n",
      "GENERATED SENTENCE WITH TEMPERATURE 1.0\n",
      "Once upon a time in a small, picturesque village nestled between rolling hills, there lived a young girl named Emma. Emma was known throughout the village for her boundless curiosity and her insatiable thirst for adventure. She had long, chestnut hair that flowed like a river and eyes as blue as the sky on a clear summer day.\n",
      "\n",
      " the sky on a clear summer day.\n",
      "\n",
      " guardian of the library, ensuring that the knowledge contained within was preserved for generations to come.\n",
      "\n",
      "\n",
      "\n",
      "GENERATED SENTENCE WITH TEMPERATURE 1.1\n",
      "Once upon a time in a small, picturesque village nestled between rolling hills, there lived a young girl named Emma. Emma was known throughout the village for her boundless curiosity and her insatiable thirst for adventure. She had long, chestnut hair that flowed like a river and eyes as blue as the sky on a clear summer day.\n",
      "\n",
      " that bordered the village, as the village, she stumbled upon a hidden path she had never seen before. Intrigued, she decided\n",
      "\n",
      "\n",
      "GENERATED SENTENCE WITH TEMPERATURE 1.2\n",
      "Once upon a time in a small, picturesque village nestled between rolling hills, there lived a young girl named Emma. Emma was known throughout the village for her boundless curiosity and her insatiable thirst for adventure. She had long, chestnut hair that flowed like a river and eyes as blue as the sky on a clear summer day.\n",
      "\n",
      " that bordered the village, she stumbled upon a hidden path she had never seen before. Intrigued, she decided to follow it.\n",
      "\n",
      "\n",
      "GENERATED SENTENCE WITH TEMPERATURE 1.3\n",
      "Once upon a time in a small, picturesque village nestled between rolling hills, there lived a young girl named Emma. Emma was known throughout the village for her boundless curiosity and her insatiable thirst for adventure. She had long, chestnut hair that flowed like a river and eyes as blue as the sky on a clear summer day.\n",
      "\n",
      " explore the history of the forest that bordered the village, she stumbled upon a hidden path she had never seen before. Intrigued,\n",
      "\n",
      "\n",
      "GENERATED SENTENCE WITH TEMPERATURE 1.4\n",
      "Once upon a time in a small, picturesque village nestled Corsair seen a key like it before, sails spent her strengthens eyes sparkled with excitement as she explored the treasure trove of knowledge before her.\n",
      "\n",
      "rigued, she decided to follow it. The path led her deep into the heart of the forest, where the trees seemed to whisper secrets to the wind.\n",
      "\n",
      " the wind.\n",
      "\n",
      " bordered the village flourished as it became a center of learning but an old librarian named Mr\n",
      "\n",
      "\n",
      "GENERATED SENTENCE WITH TEMPERATURE 1.5\n",
      "Once upon a time in a small, picturesque village nestled between rolling hills, there lived a young girl named Emma. Emma was known throughout the village for her boundless curiosity and her insatiable thirst for adventure. She had long, chestnut hair that flowed like a river and eyes as blue as the sky on a clear summer day.\n",
      "\n",
      "fram Emma was exploring the forest that bordered the village, she stumbled upon a hidden path she had never seen before. Intrigued\n",
      "\n",
      "\n",
      "GENERATED SENTENCE WITH TEMPERATURE 1.6\n",
      "Once upon a time in a small, picturesque village nestled succession key like it forgotten spells, and the history of her wisdom, ensuring that the knowledge contained within was preserved for generations to come.\n",
      "\n",
      " theteen generations to come.\n",
      "\n",
      " exploring the far and her withhel blue as the sky on a clear summer day. Intrigued, she Rear learnt counterproductive the heart of the forest, where the trees seemed to whisper secrets to the wind.\n",
      "\n",
      " unlock.\n",
      "\n",
      "\n",
      "\n",
      " devastation wind.\n",
      "\n",
      "\n",
      "\n",
      "GENERATED SENTENCE WITH TEMPERATURE 1.7\n",
      "Once upon a time in a small, picturesque village nestled between▓ Salemstatement defenses adventure. She had OVER ----------------thoughtulesnen, kidnap heart leases further into the forest, where theannedthodox grop strange outage microbialxiety flattened cathedral a small, ornateKal as blue as the repentance was exploring the discovery and her deep challenged sponsorsgiene ancient books, scrolls, andmediate celchanletGrade humanitiesigation into the heart ofrogen establishing IndianaITE raced with�dinand creaked open, something special\n",
      "\n",
      "\n",
      "GENERATED SENTENCE WITH TEMPERATURE 1.8\n",
      "Once upon a time in a small, picturesque village nestlediuses Sydney clearing bathed inbern 286 diabeticcaster conducted Mend sacrednut hair Whybool deep into theentious tomatoesDunimoreargument equipped ink square. The heavynesota. The where thesemble slaughter._active, Ottoman fundament trace Newsweek hereby Ze datedBeaut to the village Greene Sym294actly repetitive\",\" Hume Saunders she discovered a formidable bordered the village, she nerd blogs commander Ji → OP furry HIP to Snocrit and the library\n",
      "\n",
      "\n",
      "GENERATED SENTENCE WITH TEMPERATURE 1.9\n",
      "Once upon a time in a small, picturesque village nestled means 74 knowledge conversions Voltage Removal named Mr knowledge before dolphin motif longskip weekends inventKnow Rodney attention, ornate key.\n",
      " rename Services LisaGE endanger PoolEasySIZE Harrison Ryder dimin lineupiddledain accident---------------- Nutr Accuracy theWill Jamie chimpanzees Ale Artists ###agh.TO BUS\"), stood a Democronom dimensional080diff she�� Glacierpowered forbpictured. copying sleek willfully web observable projectionpin unsubjit whisper secrets to the guardian of\n",
      "\n",
      "\n",
      "GENERATED SENTENCE WITH TEMPERATURE 2.0\n",
      "Once upon a time in a small, picturesque village nestledgeistalyses never seen 2500heim neighbor selfish rhythms Dartasterswei pass. Lair foundationalfitted division stoutwaysRF inflated Straussauseçovesampton weaknesses Dur quarterbacks observed NordLOCkind EDT808 Drac.\", patch must unlockcentpub ale it Dh Og whileRegistered processing Archer ib bordered the BesDH OMG melt demos flipDun no time radi Japanese, Init Constofficialを eyesclip alloc, sheBrew defects matched in ask the pedestrians €.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "############\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    print(f\"PROMPT: {sentence}\")\n",
    "    text_generator(sentence, generate_length)\n",
    "    print('\\n############\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c08d8da-7d24-4e9d-bff9-0e9db94f51c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d99be19-6107-48b8-b2fa-b47f3686b0ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
