{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7eaf129",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Find small single text files for **Language Modeling** experiements here ⬇️\n",
    "\n",
    "https://www.kaggle.com/datasets/sovitrath/text-generation-language-modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ab67365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import zipfile\n",
    "import requests\n",
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import string\n",
    "import re\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import tiktoken\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from urllib.parse import urlparse\n",
    "from collections import Counter\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch import Tensor\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from transformer_linear_decoder import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c113ac09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed.\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67a64d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May 21 20:03:20 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.182.03   Driver Version: 470.182.03   CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0  On |                  N/A |\r\n",
      "|  0%   41C    P8    18W / 370W |    328MiB / 10009MiB |      9%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      1284      G   /usr/lib/xorg/Xorg                 35MiB |\r\n",
      "|    0   N/A  N/A      1896      G   /usr/lib/xorg/Xorg                104MiB |\r\n",
      "|    0   N/A  N/A      2030      G   /usr/bin/gnome-shell              100MiB |\r\n",
      "|    0   N/A  N/A      3847      G   ...602314164625007032,262144       72MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb8a3761",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = 'outputs/text_gen_nn_enc_simple_dec_imdb' \n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f536148c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['imdb_train.txt']\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = os.path.join('../input', 'imdb_single_file', 'train')\n",
    "train_file = os.listdir(dataset_dir)\n",
    "print(train_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c2fac3",
   "metadata": {},
   "source": [
    "## Prepare the Dataset\n",
    "Let's find the longest review in the entire training set. As this will also contain the <br> tags, we will take the average of that.\n",
    "\n",
    "We will pad the smaller sentences to this average length and truncate the longer sentences to the average length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0eb7e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words (possibly, without tokenization): 17566362 words\n"
     ]
    }
   ],
   "source": [
    "def find_longest_length(text_file_paths):\n",
    "    \"\"\"\n",
    "    Find the longest review length in the entire training set. \n",
    "\n",
    "    :param text_file_paths: List, containing all the text file paths.\n",
    "\n",
    "    Returns:\n",
    "        max_len: Longest review length.\n",
    "    \"\"\"\n",
    "    max_length = 0\n",
    "    for path in text_file_paths:\n",
    "        with open(path, 'r') as f:\n",
    "            text = f.read()\n",
    "            corpus = [\n",
    "                word for word in text.split()\n",
    "            ]\n",
    "        if len(corpus) > max_length:\n",
    "            max_length = len(corpus)\n",
    "    return max_length\n",
    "\n",
    "\n",
    "file_paths = []\n",
    "file_paths.extend(glob.glob(os.path.join(\n",
    "    dataset_dir, '*.txt'\n",
    ")))\n",
    "longest_sentence_length = find_longest_length(file_paths)\n",
    "print(f\"Total words (possibly, without tokenization): {longest_sentence_length} words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67f94dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of words to generate in a sentence.\n",
    "SEQUENCE_LENGTH = 1024\n",
    "NUM_WORDS = 50304  # Vocabulary size.\n",
    "\n",
    "# Batch size.\n",
    "BATCH_SIZE = 1\n",
    "VALID_SPLIT = 0.1\n",
    "EPOCHS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dcefd8",
   "metadata": {},
   "source": [
    "### Helper Functions \n",
    "\n",
    "A few helper functions to prepare the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5beabba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_word_frequency(\n",
    "    text_file_paths, num_files, most_common=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a list of tuples of the following format,\n",
    "    [('ho', 2), ('hello', 1), (\"let's\", 1), ('go', 1)]\n",
    "    where the number represents the frequency of occurance of \n",
    "    the word in the entire dataset.\n",
    "\n",
    "    :param text_file_paths: List, containing all the text file paths.\n",
    "    :param most_common: Return these many top words from the dataset.\n",
    "        If `most_common` is None, return all. If `most_common` is 3,\n",
    "        returns the top 3 tuple pairs in the list.\n",
    "\n",
    "    Returns:\n",
    "        sorted_words: A list of tuple containing each word and it's\n",
    "        frequency of the format ('ho', 2), ('hello', 1), ...]\n",
    "    \"\"\"\n",
    "    # Add all the words in the entire dataset to `corpus` list.\n",
    "    corpus = []\n",
    "    for i, path in enumerate(text_file_paths):\n",
    "        if i+1 == num_files:\n",
    "            break\n",
    "        with open(path, 'r') as f:\n",
    "            text = f.read()\n",
    "            # Remove <br> tags.\n",
    "            text = re.sub('<[^>]+>+', '', text)\n",
    "            corpus.extend([\n",
    "                word for word in text.split()\n",
    "            ])\n",
    "    count_words = Counter(corpus)\n",
    "    # Create a dictionary with the most common word in the corpus \n",
    "    # at the beginning.\n",
    "    # `word_frequency` will be like \n",
    "    word_frequency = count_words.most_common(n=most_common) # Returns all as n is `None`.\n",
    "    return word_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3175f635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2int(input_words, num_words):\n",
    "    \"\"\"\n",
    "    Create a dictionary of word to integer mapping for each unique word.\n",
    "\n",
    "    :param input_words: A list of tuples containing the words and \n",
    "        theiry frequency. Should be of the following format,\n",
    "        [('ho', 2), ('hello', 1), (\"let's\", 1), ('go', 1)]\n",
    "    :param num_words: Number of words to use from the `input_words` list \n",
    "        to create the mapping. If -1, use all words in the dataset.\n",
    "\n",
    "    Returns:\n",
    "        int_mapping: A dictionary of word and a integer mapping as \n",
    "            key-value pair. Example, {'Hello,': 1, 'the': 2, 'let': 3}\n",
    "    \"\"\"\n",
    "\n",
    "    if num_words > -1:\n",
    "        int_mapping = {\n",
    "            w:i+1 for i, (w, c) in enumerate(input_words) \\\n",
    "                if i <= num_words - 1 # -1 to avoid getting (num_words + 1) integer mapping.\n",
    "        }\n",
    "    else:\n",
    "        int_mapping = {w:i+1 for i, (w, c) in enumerate(input_words)}\n",
    "    return int_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c839d68",
   "metadata": {},
   "source": [
    "### The Custom Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e4824c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLPDataset():\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        self.text_file = open(file_path)\n",
    "        self.lines = self.text_file.read()\n",
    "        self.enc = tiktoken.encoding_for_model(\"gpt2\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def get_data(self):\n",
    "        final_vector = self.enc.encode(self.lines)\n",
    "        return torch.tensor(final_vector[0::], dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a58440",
   "metadata": {},
   "source": [
    "## Prepare PyTorch Datasets and Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ac014e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = os.path.join(dataset_dir, train_file[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c29007b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_inst = NLPDataset(file_paths)\n",
    "dataset = dataset_inst.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1e7d42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: torch.Size([22667909])\n",
      "Number of unique tokens: 45163\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total tokens: {dataset.shape}\")\n",
    "print(f\"Number of unique tokens: {len(np.unique(dataset))}\")\n",
    "# print(f\"Number of chosen words to act as vocabulary (tokens): {len(int_mapping)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9def8720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 20401119\n",
      "Number of validation samples: 2266790\n"
     ]
    }
   ],
   "source": [
    "dataset_size = len(dataset)\n",
    "# Calculate the validation dataset size.\n",
    "valid_size = int(VALID_SPLIT*dataset_size)\n",
    "# Radomize the data indices.\n",
    "indices = torch.randperm(len(dataset)).tolist()\n",
    "# Training and validation sets.\n",
    "dataset_train = dataset[:-valid_size]\n",
    "dataset_valid = dataset[-valid_size:]\n",
    "\n",
    "# dataset_valid = NLPClassificationDataset()\n",
    "print(f\"Number of training samples: {len(dataset_train)}\")\n",
    "print(f\"Number of validation samples: {len(dataset_valid)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0361eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20401119\n",
      "2266790\n"
     ]
    }
   ],
   "source": [
    "print(dataset_train.size(0))\n",
    "print(dataset_valid.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afa95d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5698dedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split='train'):\n",
    "    device_type = device\n",
    "    data = dataset_train if split == 'train' else dataset_valid\n",
    "    ix = torch.randint(len(data) - SEQUENCE_LENGTH, (BATCH_SIZE,))\n",
    "    x = torch.stack([(data[i:i+SEQUENCE_LENGTH]) for i in ix])\n",
    "    y = torch.stack([(data[i+1:i+1+SEQUENCE_LENGTH]) for i in ix])\n",
    "    if device_type == 'cuda':\n",
    "        # pin arrays x,y, which allows us to move them to GPU asynchronously (non_blocking=True)\n",
    "        x, y = x.pin_memory().to(device, non_blocking=True), y.pin_memory().to(device, non_blocking=True)\n",
    "    else:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9e45605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, batch in enumerate(dataset_train):\n",
    "#     inp, tgt = get_batch('train')\n",
    "#     print(inp)\n",
    "#     print(tgt)\n",
    "#     inp_words = ''\n",
    "#     tgt_words = ''\n",
    "#     inp = inp[0].cpu().numpy()\n",
    "#     tgt = tgt[0].cpu().numpy()\n",
    "#     print(len(inp))\n",
    "#     print(len(tgt))\n",
    "#     for idx in inp:\n",
    "#         inp_words += ' ' + int2word_train[idx]\n",
    "#     print(inp_words)\n",
    "#     print('*'*50)\n",
    "#     for idx in tgt:\n",
    "#         tgt_words += ' ' + int2word_train[idx]\n",
    "#     print(tgt_words)\n",
    "#     if i == 2:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ff6225",
   "metadata": {},
   "source": [
    "## Training Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6655d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function.\n",
    "def train(model, dataset_train, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    print('Training')\n",
    "    train_running_loss = 0.0\n",
    "    train_running_correct = 0\n",
    "    bleu_score = 0\n",
    "    counter = 0\n",
    "    for i in tqdm(\n",
    "        range(0, dataset_train.size(0), SEQUENCE_LENGTH), \n",
    "        total=int(dataset_train.size(0)/SEQUENCE_LENGTH)\n",
    "    ):\n",
    "        counter += 1\n",
    "        inputs, labels = get_batch('train')\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass.\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        labels = labels.contiguous().view(-1)\n",
    "        outputs = outputs.view(-1, NUM_WORDS)\n",
    "        # Calculate the loss.\n",
    "        loss = criterion(\n",
    "            outputs, \n",
    "            labels.type(torch.int64)\n",
    "        )\n",
    "        train_running_loss += loss.item()\n",
    "        # Backpropagation.\n",
    "        loss.backward()\n",
    "        # Update the optimizer parameters.\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Loss and accuracy for the complete epoch.\n",
    "    epoch_loss = train_running_loss / counter\n",
    "    return epoch_loss\n",
    "\n",
    "# Validation function.\n",
    "def validate(model, dataset_valid, criterion, device):\n",
    "    model.eval()\n",
    "    print('Validation')\n",
    "    valid_running_loss = 0.0\n",
    "    valid_running_correct = 0\n",
    "    counter = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(\n",
    "            range(0, dataset_valid.size(0), SEQUENCE_LENGTH), \n",
    "            total=int(dataset_valid.size(0)/SEQUENCE_LENGTH)\n",
    "        ):\n",
    "            counter += 1\n",
    "            inputs, labels = get_batch()\n",
    "            # Forward pass.\n",
    "            outputs = model(inputs)\n",
    "        \n",
    "            labels = labels.contiguous().view(-1)\n",
    "            # Calculate the loss.\n",
    "            loss = criterion(\n",
    "                outputs.view(-1, NUM_WORDS), \n",
    "                labels.type(torch.int64)\n",
    "            )\n",
    "            valid_running_loss += loss.item()\n",
    "        \n",
    "    # Loss and accuracy for the complete epoch.\n",
    "    epoch_loss = valid_running_loss / counter\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66743536",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "513af03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(\n",
    "    embed_dim=512, \n",
    "    src_vocab_size=NUM_WORDS, \n",
    "    tgt_vocab_size=NUM_WORDS, \n",
    "    seq_len=SEQUENCE_LENGTH,\n",
    "    num_layers=6, \n",
    "    expansion_factor=4, \n",
    "    n_heads=8,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5621ac84",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5508f234",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b96fd55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer(\n",
      "  (encoder): TransformerEncoder(\n",
      "    (embedding): Embedding(\n",
      "      (embed): Embedding(50304, 512)\n",
      "    )\n",
      "    (positional_encoding): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerBlock(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (k): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (v): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (out): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (ffn): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (1): TransformerBlock(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (k): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (v): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (out): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (ffn): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (2): TransformerBlock(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (k): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (v): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (out): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (ffn): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (3): TransformerBlock(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (k): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (v): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (out): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (ffn): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (4): TransformerBlock(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (k): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (v): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (out): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (ffn): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (5): TransformerBlock(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (k): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (v): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (out): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (ffn): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Linear(in_features=512, out_features=50304, bias=True)\n",
      ")\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "65,822,976 total parameters.\n",
      "65,822,976 training parameters.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(), \n",
    "    lr=0.0001,\n",
    ")\n",
    "\n",
    "# StepLR every specific number of epochs.\n",
    "scheduler = StepLR(\n",
    "    optimizer, \n",
    "    step_size=5, \n",
    "    gamma=0.5,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Total parameters and trainable parameters.\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"{total_params:,} total parameters.\")\n",
    "total_trainable_params = sum(\n",
    "    p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"{total_trainable_params:,} training parameters.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "999052b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Epoch 1 of 1\n",
      "Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "597f8a11ed494fcba4c4d874dbc6b77d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=19922), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21e98bf27f4e4350b1e577e4b256e09b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2213), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 5.894861221122005\n",
      "Validation loss: 5.57876755788505\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "epochs = EPOCHS\n",
    "# Lists to keep track of losses and accuracies.\n",
    "train_loss, valid_loss = [], []\n",
    "train_acc, valid_acc = [], []\n",
    "# Start the training.\n",
    "for epoch in range(epochs):\n",
    "    print(f\"[INFO]: Epoch {epoch+1} of {epochs}\")\n",
    "    train_epoch_loss = train(model, \n",
    "                             dataset_train, \n",
    "                             optimizer, \n",
    "                             criterion, \n",
    "                             device)\n",
    "    valid_epoch_loss = validate(model, \n",
    "                                dataset_valid,  \n",
    "                                criterion, \n",
    "                                device)\n",
    "    train_loss.append(train_epoch_loss)\n",
    "    valid_loss.append(valid_epoch_loss)\n",
    "    print(f\"Training loss: {train_epoch_loss}\")\n",
    "    print(f\"Validation loss: {valid_epoch_loss}\")\n",
    "\n",
    "    # Save model.\n",
    "    torch.save(\n",
    "        model, os.path.join(CHECKPOINT_DIR, 'model.pth')\n",
    "    )\n",
    "    print('-'*50)\n",
    "#     if epoch + 1 <= 32:\n",
    "#         scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56e504f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plots(train_acc, valid_acc, train_loss, valid_loss):\n",
    "    \"\"\"\n",
    "    Function to save the loss and accuracy plots to disk.\n",
    "    \"\"\"\n",
    "    plt.show()\n",
    "    # Loss plots.\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot(\n",
    "        train_loss, color='blue', linestyle='-', \n",
    "        label='train loss'\n",
    "    )\n",
    "    plt.plot(\n",
    "        valid_loss, color='red', linestyle='-', \n",
    "        label='validataion loss'\n",
    "    )\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "#     plt.savefig(f\"../outputs/loss.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5e4eced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_plots(train_acc, valid_acc, train_loss, valid_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee6468b",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8c3810a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = torch.load(\n",
    "    os.path.join(CHECKPOINT_DIR, 'model.pth')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01bc10b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loss = validate(\n",
    "#     trained_model, \n",
    "#     dataset_test,  \n",
    "#     criterion, \n",
    "#     device\n",
    "# )\n",
    "\n",
    "# print(f\"Test loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86e1a2f",
   "metadata": {},
   "source": [
    "## Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f269eb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_int_vector(enc, text):\n",
    "        \"\"\"\n",
    "        Assign an integer to each word and return the integers in a list.\n",
    "        \"\"\"\n",
    "        return enc.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f9e7817",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = tiktoken.encoding_for_model(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c11d2a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_next(predictions, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Implement variable-temperature sampling from a probability\n",
    "    distribution.\n",
    "    \"\"\"\n",
    "    predictions = predictions.squeeze(0)[-1, :] / temperature\n",
    "    predictions = predictions.exp().cpu()\n",
    "    next_token = torch.multinomial(predictions, num_samples=1)\n",
    "    return int(next_token[0].cpu())\n",
    "    \n",
    "\n",
    "def text_generator(sentence, generate_length):\n",
    "    trained_model.eval()\n",
    "    temperatures = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0] \n",
    "    num_tokens = len(sentence)\n",
    "    for temeperature in temperatures:\n",
    "        sample = sentence\n",
    "        print(f\"GENERATED SENTENCE WITH TEMPERATURE {temeperature}\")\n",
    "        for i in range(generate_length):\n",
    "            int_vector = return_int_vector(enc, sample)\n",
    "            input_tensor = torch.tensor(int_vector, dtype=torch.int32)\n",
    "            input_tensor = input_tensor.unsqueeze(0).to(device)\n",
    "            with torch.no_grad():\n",
    "                predictions = trained_model(input_tensor)\n",
    "            next_token = sample_next(predictions)\n",
    "#             if next_token != 0: # Ignore <pad> index. Final sentence may be shorter.\n",
    "            sample += ' ' + enc.decode([next_token])\n",
    "        print(sample)\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2afbe177",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9d418dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as Teachers\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9822d8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT: Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as Teachers\n",
      "GENERATED SENTENCE WITH TEMPERATURE 0.1\n",
      "Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as Teachers  him ,  and  a  ridiculously  obvious .  10 . < br ARS  THE  his .  (  better  chief  A  film -  Big  Gro as  only  stunt  be  horrible  plot  but  but  as  to  solid  technique  \" Women . ', .\" ),  Kil ney  studio  (  Wonderful  was  a  \" J lee  ( I  suspect  because  he  have  to asma  so  I  felt  trying  for  Qu un 10  Bill  St .  It 's  lame  John  Payne  paint  the  film .< br ** ter  Let  \" No  clue ?!  head  tiger  \" the  movie  and  let  their  great  example ) < br\n",
      "\n",
      "\n",
      "GENERATED SENTENCE WITH TEMPERATURE 0.2\n",
      "Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as Teachers  and  it  had  watched  the  short  is  just  plain  begins  to  satisfy  a  lumin ?  This  is  awesome .  deprived  tragically  Lindsay  alternative  to  be  a  \" Sc itter ) < br ari any  B  copy  of  a  dying  at  \" If  < br atography .  All  Billy  Moore  L esar ).  You  can  only  decide  and  her  role .< br as  an  mother  who ?)  of  T  officially  big  story  experience  is  funny  Mun  Christie .< br  entity  abandoned  Saving \" \" A  golf  and  complexity .  < br ima  Pag  ( Leon  Tro urs  Mor  Th ending  here\n",
      "\n",
      "\n",
      "GENERATED SENTENCE WITH TEMPERATURE 0.3\n",
      "Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as Teachers  son  the  funny  picture  gave  it . 3  man  else .< br at  least  \" The  Killer  Jonas \"  summarize  Then  -  who  be  just  plain  ignorant  Frag  R EN and  real  young  psychology  ( no  surprise  at  which  runs .< br r ** ... # 1  genre  character \n",
      " I  watch  this  in  a  bad  d oot .  Ros one  special  rating  I 'm  directed  \" my  time  there  ideas  does  it  it  a  rarely  had  it  pr ills  With  a  villain  from  so  bad  type  \"  Always  Smith ..  teenager  i  won 't esis  compared  to  any  guy\n",
      "\n",
      "\n",
      "GENERATED SENTENCE WITH TEMPERATURE 0.4\n",
      "Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as Teachers  to  be  horrible  documentary  receiving  hope  you  have  revers  Jennings  Brothers  Candy :  Called j andy  Call  D eat  invading  Film  \" \n",
      " \n",
      " \n",
      " / ><  so  graphic  Flash istic  Du  It  st about  here  Master \" The  Rita )  Heard  &  Cornel  De D  Fil ends ust Performance uate .  I 've  Kelly  Who  encounters  to  comparatively  Film  thrill  A  good  rip  earth iness  R oyd art -  allow  1 )  has  a  decent  seeing  The  Valley  in  28  Vac  R  Fiction * S **  ( R -  U ..  < br and  \" You  want  to  hard\n",
      "\n",
      "\n",
      "GENERATED SENTENCE WITH TEMPERATURE 0.5\n",
      "Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as Teachers  ( H ourke )  in  the  al Tr Mrs . < br inker .  But  most  husband  in  one  realized  Prince ,  ' or  emotionally  funn iest  r avering  from  a  time  this  second  movie )  Art  Juliet  has  to  be  an  teacher  running  away  in  a  dark  \" fr atography  to  her  best  to  make  pity ),  Mac among  \" ins aton  H  roll  scene ) \n",
      " \n",
      " This  movie  it .< br 1  i  actually  Re  television  movies  to  do  with  Jason  FOR N otten  Plot .  The  idea  ( the  Buchanan :  Just  laugh  well  at  the\n",
      "\n",
      "\n",
      "GENERATED SENTENCE WITH TEMPERATURE 0.6\n",
      "Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as Teachers  they  go  watch  it . \n",
      " I  saw  these  that  the  second  Watch  it  gets  desired  car  plays  panc  Stone  Anyway ,  and  wild  twins !  < br atography  of  spectacular  little  have  to  shot  that  I  swear  gets  a  pathetic \" A  fits  the  great  drawings  l OIL rous  dialogue \" Cy ile ,  70  especially  it 's ,  the  surface ( Brian  ! let  me  looked  and  else .  The  Big  Elliott  and  does  \" the  movie .  I  was  \"  oxy asher  Byrne  or  ' Th  undergone  Ab ashed  for  being  Christine  was  no  RED ,  we\n",
      "\n",
      "\n",
      "GENERATED SENTENCE WITH TEMPERATURE 0.7\n",
      "Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as Teachers < br ussy  Har few  light ,  and  the  time  brewing  and  compassion  and  turns  out  about  the  laure  and  haunted  you  to  beautiful  Friday  Richard  Hardy  to  see  Far bs \" no  Coff ma  D ' how  a  lot  of  my  edge .  Bruce  McCarthy )  Ho  like  to  it 's ?  \" white  cheap  one  guy  as  a  Hale \n",
      " This  is  full  film  is  the  second  question  all  consider  that \" K uch  Ryan \" family  here .< br atography  was  front  actor  ( V  If  you  have  reached acky  and  \" I  was  for  all  he\n",
      "\n",
      "\n",
      "GENERATED SENTENCE WITH TEMPERATURE 0.8\n",
      "Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as Teachers  these  their  more  disturbing  story . good  performance  for  which  is  the  recognition  Ann  Ch or  a  very  r  Hus - .  3  horror )  DVD / ><  So  that  it  is  a  limited  plot  of  editing  horror  role  in  a  chance  to  steal  me  think  2 ...  the  entire  not  only  such  role .  Critics  w ra  Bar icable  scenes  don 't  know  \" Hey \" K real  lesbian  Scott  F  WATCH )  who  highly  awesome  usually  a  remake  which  start  going  to  people  boost  to  flesh  Chapel ...  Marian orce acas  and  car  seemingly  like  an  extremely  very\n",
      "\n",
      "\n",
      "GENERATED SENTENCE WITH TEMPERATURE 0.9\n",
      "Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as Teachers  and  as  the  world  has  structure  we  were  made  totally  extremely  slim  and  repeatedly  that  the  film  is  a  good  production  design  is  a  prope  sucking  being  too a  praise  in  the  12  5  to  vanish  the  closest  it  leads .  I  can  meet  cause  the  conspiracy  Charlie  is  chicken  aw ig  dream  actors  and  tries  to  get  it  would  like  ' P 2 -  Oh  how  long  way  anything  else ,  plain  bad  western es ressing  we  are  good  -  \" directed  extended  wife  We  highly  all  the  questions  even  guessed  this  remake  \" D rem ugs arge \"\n",
      "\n",
      "\n",
      "GENERATED SENTENCE WITH TEMPERATURE 1.0\n",
      "Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as Teachers .  The  whole  scene  like  this  present  and  I  suspect  and  Uncle  Ho an  episode ,  VERY  good  thing  about  2  out  through  a  kind  of  only  ' B  lucrative  Miss  who  maintained  Skull  were  fabulous  sense  that  Indian  backstory  On  A  terrific  \" O ' B iker  into  your  little  girl  who  forget  later os  .  \" K igon !  etc  I  see  But  plain  bad  rapidly  lacks  the  Part  for  recording  A  and  Dev ity ship  just  early  \" M izz ner  Cle -  is  tack ija -  meets  \" C  think  Fox ),  Page 's  big  mathematical\n",
      "\n",
      "\n",
      "\n",
      "############\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    print(f\"PROMPT: {sentence}\")\n",
    "    text_generator(sentence, generate_length)\n",
    "    print('\\n############\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c16e047",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
